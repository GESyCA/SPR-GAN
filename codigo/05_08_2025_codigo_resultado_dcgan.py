# -*- coding: utf-8 -*-
"""05_08_2025_codigo_resultado_DCGAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10uPxslBNuFZjE0ijhA-COVVYIp5MvX-7

#Gerando amostras do conjunto de dados SPR usando Deep Convolutional GANs - (DCGAM)
"""

import torch
import os
import torchvision
import torchvision.transforms as transforms
import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import numpy as np
import torch.optim as optim
import zipfile
from torch.utils.data import random_split, DataLoader

from torchvision import datasets, transforms
from torch.utils.data import DataLoader
#Montar o Google Drive
from google.colab import drive
drive.mount('/content/drive')

# definir dispositivo
device = torch.device("cpu")

###################################################
caminho_trainloader = "/content/drive/My Drive/mestrado_16_03_2024/224X224_14_04_2025/IMAGENS_SIMULADAS_RPS_C1/trainloader"#monocromantica
caminho_testloader = "/content/drive/My Drive/mestrado_16_03_2024/224X224_14_04_2025/IMAGENS_SIMULADAS_RPS_C1/testloader"##monocromantica
caminho_img_133_1335_11 = "/content/drive/My Drive/mestrado_16_03_2024/224X224_14_04_2025/img_133_1335_11"##monocromantica
caminho_IMAGENS_GERADA_DCGAN = "/content/drive/My Drive/mestrado_16_03_2024/224X224_14_04_2025/IMAGENS_GERADA_DCGAN"
caminho_IMG_GERADA_INTERPOLDASA_133_135 = "/content/drive/My Drive/mestrado_16_03_2024/224X224_14_04_2025/IMG_GERADA_+_INTERPOLDASA_133_135"
caminho_IMG_GERADA_INTERPOLDASA_133_1335 = "/content/drive/My Drive/mestrado_16_03_2024/224X224_14_04_2025/IMG_GERADA_+_INTERPOLDASA_133_1335"




# Transformação das imagens
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),  # Converter para escala de cinza
    transforms.Resize((224, 224)),                # Redimensionar para 224x224
    transforms.ToTensor(),                        # Converter para tensor
    transforms.Normalize((0.5,), (0.5,))          # Normalizar para [-1, 1]
])

# Criando uma classe personalizada para o Dataset que também retorna o nome da imagem
class CustomImageFolder(datasets.ImageFolder):
    def __getitem__(self, index):
        image, label = super().__getitem__(index)  # Obtém a imagem transformada e o rótulo
        image_path = self.imgs[index][0]  # Caminho completo da imagem
        image_name = os.path.basename(image_path)  # Obtém apenas o nome do arquivo

        return image, label, image_name  # Retorna a imagem, rótulo e nome do arquivo

# Criar o dataset usando a classe CustomImageFolder
dataset_trainloader = CustomImageFolder(root=caminho_trainloader, transform=transform)
dataset_testloader = CustomImageFolder(root=caminho_testloader, transform=transform)
dataset_img_133_1335_11 = CustomImageFolder(root=caminho_img_133_1335_11, transform=transform)

dataset_IMAGENS_GERADA_DCGAN_1 = CustomImageFolder(root=caminho_IMAGENS_GERADA_DCGAN, transform=transform)
dataset_IMG_GERADA_INTERPOLDASA_133_135_1 = CustomImageFolder(root=caminho_IMG_GERADA_INTERPOLDASA_133_135, transform=transform)
dataset_IMG_GERADA_INTERPOLDASA_133_1335_1 = CustomImageFolder(root=caminho_IMG_GERADA_INTERPOLDASA_133_1335, transform=transform)



trainloader = DataLoader(dataset_trainloader, batch_size=1, shuffle=True, num_workers=0)# Tem 108 imagens cada classe, totalizando 540imagens
testloader = DataLoader(dataset_testloader, batch_size=1, shuffle=True, num_workers=0)# # Tem 12 imagens cada classe, totalizando 60 imagens

dataset_IMAGENS_GERADA_DCGAN_2 = DataLoader(dataset_IMAGENS_GERADA_DCGAN_1, batch_size=1, shuffle=True, num_workers=0)# # Tem 12 imagens cada classe, totalizando 60 imagens
dataset_IMG_GERADA_INTERPOLDASA_133_135_2 = DataLoader(dataset_IMG_GERADA_INTERPOLDASA_133_135_1, batch_size=1, shuffle=True, num_workers=0)# # IMAGENS GERADA PELA DCGAN
dataset_IMG_GERADA_INTERPOLDASA_133_1335_2 = DataLoader(dataset_IMG_GERADA_INTERPOLDASA_133_1335_1, batch_size=1, shuffle=True, num_workers=0)# # IMAGENS GERADA PELA DCGAN
#########################################################################################

########################Arquitetura da Rede Discriminadora###############################

class Discriminator(nn.Module):
    def __init__(self, d_n):
        super(Discriminator, self).__init__()

        self.conv1 = nn.Conv2d(1, d_n, 4, 2, 1, bias=False)  # 224x224 -> 112x112
        self.conv2 = nn.Conv2d(d_n, d_n*2, 4, 2, 1, bias=False)  # 112x112 -> 56x56
        self.conv3 = nn.Conv2d(d_n*2, d_n*4, 4, 2, 1, bias=False)  # 56x56 -> 28x28
        self.conv4 = nn.Conv2d(d_n*4, d_n*8, 4, 2, 1, bias=False)  # 28x28 -> 14x14
        self.conv5 = nn.Conv2d(d_n*8, d_n*16, 4, 2, 1, bias=False)  # 14x14 -> 7x7
        self.conv6 = nn.Conv2d(d_n*16, 1, 7, 1, 0, bias=False)  # 7x7 -> 1x1

    def forward(self, x):  # a entrada é 1 x 224 x 224
        x = F.leaky_relu(self.conv1(x), 0.2)  # state size: d_n x 112 x 112
        x = F.leaky_relu(self.conv2(x), 0.2)  # state size: (2*d_n) x 56 x 56
        x = F.leaky_relu(self.conv3(x), 0.2)  # state size: (4*d_n) x 28 x 28
        x = F.leaky_relu(self.conv4(x), 0.2)  # state size: (8*d_n) x 14 x 14
        x = F.leaky_relu(self.conv5(x), 0.2)  # state size: (16*d_n) x 7 x 7
        x = torch.sigmoid(self.conv6(x))  # state size: 1 x 1 x 1
        return x

#########################################################################################
###########################Gerando Pontos Latente########################################
def generateLatentPoints(batch_size, z_i):
    z = torch.randn(batch_size, z_i, 1, 1, device=device)
    return z
#########################################################################################
###########################Arquitetura da Rede Geradora##################################
import torch
import torch.nn as nn
import torch.nn.functional as F

class Generator(nn.Module):
    def __init__(self, z_i, g_n):
        super(Generator, self).__init__()

        self.conv1 = nn.ConvTranspose2d(z_i, g_n*16, 7, 1, 0, bias=False)  # 1x1 -> 7x7
        self.batchNorm1 = nn.BatchNorm2d(g_n*16)
        self.conv2 = nn.ConvTranspose2d(g_n*16, g_n*8, 4, 2, 1, bias=False)  # 7x7 -> 14x14
        self.batchNorm2 = nn.BatchNorm2d(g_n*8)
        self.conv3 = nn.ConvTranspose2d(g_n*8, g_n*4, 4, 2, 1, bias=False)  # 14x14 -> 28x28
        self.batchNorm3 = nn.BatchNorm2d(g_n*4)
        self.conv4 = nn.ConvTranspose2d(g_n*4, g_n*2, 4, 2, 1, bias=False)  # 28x28 -> 56x56
        self.batchNorm4 = nn.BatchNorm2d(g_n*2)
        self.conv5 = nn.ConvTranspose2d(g_n*2, g_n, 4, 2, 1, bias=False)  # 56x56 -> 112x112
        self.batchNorm5 = nn.BatchNorm2d(g_n)
        self.conv6 = nn.ConvTranspose2d(g_n, 1, 4, 2, 1, bias=False)  # 112x112 -> 224x224

    def forward(self, x):
        # a entrada é (z_i) x 1 x 1
        x = F.leaky_relu(self.batchNorm1(self.conv1(x)), 0.2)  # state size: (16*g_n) x 7 x 7
        x = F.leaky_relu(self.batchNorm2(self.conv2(x)), 0.2)  # state size: (8*g_n) x 14 x 14
        x = F.leaky_relu(self.batchNorm3(self.conv3(x)), 0.2)  # state size: (4*g_n) x 28 x 28
        x = F.leaky_relu(self.batchNorm4(self.conv4(x)), 0.2)  # state size: (2*g_n) x 56 x 56
        x = F.leaky_relu(self.batchNorm5(self.conv5(x)), 0.2)  # state size: (g_n) x 112 x 112
        x = torch.tanh(self.conv6(x))  # state size: 1 x 224 x 224
        return x
###################################################################
######################Inicializando Pesos##########################

def initWeights(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

#########################################################################################
######################Criando, treinando e validando os modelos##########################

# hiperparâmetros do discriminador e do gerador"
z_i = 100 # tamanho da entrada da distribuição aleatória
d_n = 64 # São as características para usar na rede discriminadora
g_n = 64 # São as características para usar na rede geradora

# iniciar a rede discriminadora
D = Discriminator(d_n).to(device)
D.apply(initWeights)

# iniciar a rede geradora
G = Generator(z_i, g_n).to(device)
G.apply(initWeights)

############################################################
# Otimizador responsável por atualizar os parâmetros do Gerador durante o treinamento.
# lr (taxa de aprendizado): Define o tamanho do passo a cada atualização no treinamento.
# betas: Parâmetros do Adam que ajudam a manter a estabilidade durante o treinamento.
d_optimizer = optim.Adam(D.parameters(), lr = 0.00001, betas=(0.5, 0.999))

############################################################

# Otimizador responsável por atualizar os parâmetros do Gerador durante o treinamento.
# lr (taxa de aprendizado): Define o tamanho do passo a cada atualização no treinamento.
# betas: Parâmetros do Adam que ajudam a manter a estabilidade durante o treinamento.
g_optimizer = optim.Adam(G.parameters(), lr=0.00001, betas=(0.5, 0.999))

############################################################

# hiperparâmetros de treinamento
maxEpochs = 50



#########################################################################################
###############Buscar a "perda do gerador" e a "perda do discriminador"##################

import json


loss_data_path = '/content/drive/My Drive/mestrado_16_03_2024/224X224_24_03_2025/Loss_salvo_DCGAM/30_01_2025_img_rps_c1_lr_0_00001_50_loss_data.json'


# Lê os dados do arquivo JSON
with open(loss_data_path, 'r') as f:
    loss_data = json.load(f)

d_loss_ = loss_data['d_loss_']
g_loss_ = loss_data['g_loss_']

#########################################################################################
##############################Buscar o modelo treinado"##################################

PATH_G = '/content/drive/My Drive/mestrado_16_03_2024/224X224_24_03_2025/Modelo_salvo_DCGAM/30_01_2025_img_spr_c1_lr_0.00001_Modelo_salvo_G_50_epochs.pt'


# Recria as instâncias das classes do gerador
G = Generator(z_i, g_n).to(device)
# Carrega o state_dict salvo nos modelos
G.load_state_dict(torch.load(PATH_G))
# Coloca os modelos em modo de avaliação
G.eval()

# função para imprimir as perdas do modelo
def printLosses(d_loss, g_loss, save=False):
    plt.plot(d_loss, label='Perda do Discriminador', c='blue')
    plt.plot(g_loss, label='Perda do Gerador', c='red')
   # plt.title('Perdas do Treinamento')
    plt.xlabel('Épocas')
    plt.ylabel('Perda')
    plt.legend()

    if save:
        plt.savefig('image:losses.png')
    plt.show()
import json
from google.colab import drive

# Montar o Google Drive
drive.mount('/content/drive')

loss_data_path = '/content/drive/My Drive/mestrado_16_03_2024/224X224_24_03_2025/Loss_salvo_DCGAM/30_01_2025_img_rps_c1_lr_0_00001_50_loss_data.json'


# Lê os dados do arquivo JSON
with open(loss_data_path, 'r') as f:
    loss_data = json.load(f)

d_loss_ = loss_data['d_loss_']
g_loss_ = loss_data['g_loss_']


printLosses(d_loss_, g_loss_, save=True)
## EXPLICAR COMO É ESSA EPOCA NA DCGAN?

import matplotlib.pyplot as plt
import torch
import math

def printImages3(images, ids=None):
    num_images = len(images)
    rows = math.ceil(num_images / 10)  # Número de linhas baseado em 10 colunas
    cols = 10  # 10 colunas fixas

    fig, axes = plt.subplots(rows, cols, figsize=(12, rows + 0.5))  # Ajuste para caber os IDs
    axes = axes.flatten()  # Transforma em uma lista plana de eixos

    for i, img in enumerate(images):
        img_array = img.squeeze()  # Remove dimensões extras

        if isinstance(img_array, torch.Tensor):
            img_array = img_array.cpu().numpy()  # Converte para NumPy se for tensor

        # Remove canal de cor se for (1, H, W)
        if img_array.ndim == 3 and img_array.shape[0] == 1:
            img_array = img_array[0]

        if img_array.ndim == 2:
            axes[i].imshow(img_array, cmap='gray', interpolation='nearest')
            axes[i].axis('off')  # Remove eixos

            # Adiciona o ID abaixo da imagem (se existir)
            if ids is not None and i < len(ids):
                axes[i].set_title(f"{ids[i]}", fontsize=8, pad=2)  # `pad` ajusta distância
        else:
            raise ValueError(f"Formato inválido da imagem: {img_array.shape}")

    # Desativa subplots não usados
    for j in range(num_images, len(axes)):
        axes[j].axis('off')

    plt.tight_layout()
    plt.show()

import matplotlib.pyplot as plt
import matplotlib.patches as mpatches

# Dados das imagens geradas
dados_gerados = [
   ("imagem_gerada_11_c1_4_img_1.33_guassblur_10.jpg", 1.33, -5.6085, -6.4974),
    ("imagem_gerada_12_c1_4_img_1.33_guassblur_2.jpg", 1.33, -5.7710, -6.2379),
    ("imagem_gerada_15_c1_4_img_1.33_guassblur_10.jpg", 1.33, -6.2108, -6.7494),
    ("imagem_gerada_16_c1_4_img_1.33_guassblur_2.jpg", 1.33, -6.2046, -6.8703),
    ("imagem_gerada_17_c1_4_img_1.33_guassblur_10.jpg", 1.33, -5.8451, -6.5771),
    ("imagem_gerada_18_c1_4_img_1.33_guassblur_2.jpg", 1.33, -5.8520, -7.5814),
    ("imagem_gerada_1_c1_4_img_1.33_guassblur_10.jpg", 1.33, -5.6961, -6.2548),
    ("imagem_gerada_2_c1_4_img_1.33_guassblur_2.jpg", 1.33, -5.6630, -6.8557),
    ("imagem_gerada_5_c1_4_img_1.33_guassblur_10.jpg", 1.33, -4.7576, -6.7236),
    ("imagem_gerada_6_c1_4_img_1.33_guassblur_2.jpg", 1.33, -6.2488, -6.7902),
    ("imagem_gerada_7_c1_4_img_1.33_guassblur_10.jpg", 1.33, -5.5863, -6.7729),
    ("imagem_gerada_8_c1_4_img_1.33_guassblur_2.jpg", 1.33, -5.6740, -6.6251),
    ("imagem_gerada_11_c1_4_img_1.335_guassblur_10.jpg", 1.335, -2.4565, -2.9373),
    ("imagem_gerada_12_c1_4_img_1.335_guassblur_2.jpg", 1.335, -2.5308, -2.6667),
    ("imagem_gerada_15_c1_4_img_1.335_guassblur_10.jpg", 1.335, -2.8568, -1.6950),
    ("imagem_gerada_16_c1_4_img_1.335_guassblur_2.jpg", 1.335, -1.9443, -2.8315),
    ("imagem_gerada_17_c1_4_img_1.335_guassblur_10.jpg", 1.335, -2.3175, -3.3280),
    ("imagem_gerada_18_c1_4_img_1.335_guassblur_2.jpg", 1.335, -2.1320, -2.6496),
    ("imagem_gerada_1_c1_4_img_1.335_guassblur_10.jpg", 1.335, -2.3797, -2.6069),
    ("imagem_gerada_2_c1_4_img_1.335_guassblur_2.jpg", 1.335, -1.9540, -3.2026),
    ("imagem_gerada_5_c1_4_img_1.335_guassblur_10.jpg", 1.335, -1.9315, -2.9003),
    ("imagem_gerada_6_c1_4_img_1.335_guassblur_2.jpg", 1.335, -2.3996, -1.8914),
    ("imagem_gerada_7_c1_4_img_1.335_guassblur_10.jpg", 1.335, -2.2808, -2.9655),
    ("imagem_gerada_8_c1_4_img_1.335_guassblur_2.jpg", 1.335, -2.2301, -3.2774),
    ("imagem_gerada_11_c1_4_img_1.34_guassblur_10.jpg", 1.34, 1.9168, 1.8054),
    ("imagem_gerada_12_c1_4_img_1.34_guassblur_2.jpg", 1.34, 1.9536, 1.7948),
    ("imagem_gerada_15_c1_4_img_1.34_guassblur_10.jpg", 1.34, 2.3644, 2.0598),
    ("imagem_gerada_16_c1_4_img_1.34_guassblur_2.jpg", 1.34, 2.4580, 2.2338),
    ("imagem_gerada_17_c1_4_img_1.34_guassblur_10.jpg", 1.34, 2.6238, 1.6977),
    ("imagem_gerada_18_c1_4_img_1.34_guassblur_2.jpg", 1.34, 2.4205, 1.5458),
    ("imagem_gerada_1_c1_4_img_1.34_guassblur_10.jpg", 1.34, 2.2041, 1.6293),
    ("imagem_gerada_2_c1_4_img_1.34_guassblur_2.jpg", 1.34, 1.5981, 1.9665),
    ("imagem_gerada_5_c1_4_img_1.34_guassblur_10.jpg", 1.34, 2.0006, 1.6789),
    ("imagem_gerada_6_c1_4_img_1.34_guassblur_2.jpg", 1.34, 2.7845, 1.9785),
    ("imagem_gerada_7_c1_4_img_1.34_guassblur_10.jpg", 1.34, 1.2318, 1.1036),
    ("imagem_gerada_8_c1_4_img_1.34_guassblur_2.jpg", 1.34, 2.4232, 1.4728),
    ("imagem_gerada_11_c1_4_img_1.345_guassblur_10.jpg", 1.345, 6.0410, 8.0119),
    ("imagem_gerada_12_c1_4_img_1.345_guassblur_2.jpg", 1.345, 7.1721, 7.6884),
    ("imagem_gerada_15_c1_4_img_1.345_guassblur_10.jpg", 1.345, 7.8744, 7.7403),
    ("imagem_gerada_16_c1_4_img_1.345_guassblur_2.jpg", 1.345, 8.0485, 7.3526),
    ("imagem_gerada_17_c1_4_img_1.345_guassblur_10.jpg", 1.345, 7.7115, 7.2047),
    ("imagem_gerada_18_c1_4_img_1.345_guassblur_2.jpg", 1.345, 7.5976, 7.2577),
    ("imagem_gerada_1_c1_4_img_1.345_guassblur_10.jpg", 1.345, 7.5511, 7.6477),
    ("imagem_gerada_2_c1_4_img_1.345_guassblur_2.jpg", 1.345, 7.2817, 7.6628),
    ("imagem_gerada_5_c1_4_img_1.345_guassblur_10.jpg", 1.345, 8.1458, 7.6412),
    ("imagem_gerada_6_c1_4_img_1.345_guassblur_2.jpg", 1.345, 7.0514, 9.1799),
    ("imagem_gerada_7_c1_4_img_1.345_guassblur_10.jpg", 1.345, 7.7885, 7.2081),
    ("imagem_gerada_8_c1_4_img_1.345_guassblur_2.jpg", 1.345, 7.4998, 7.2853),
    ("imagem_gerada_11_c1_4_img_1.35_guassblur_10.jpg", 1.35, 9.9163, 10.6072),
    ("imagem_gerada_12_c1_4_img_1.35_guassblur_2.jpg", 1.35, 9.7943, 10.7158),
    ("imagem_gerada_15_c1_4_img_1.35_guassblur_10.jpg", 1.35, 9.7105, 10.4177),
    ("imagem_gerada_16_c1_4_img_1.35_guassblur_2.jpg", 1.35, 8.2511, 9.9663),
    ("imagem_gerada_17_c1_4_img_1.35_guassblur_10.jpg", 1.35, 6.9703, 9.3682),
    ("imagem_gerada_18_c1_4_img_1.35_guassblur_2.jpg", 1.35, 10.1078, 10.3473),
    ("imagem_gerada_1_c1_4_img_1.35_guassblur_10.jpg", 1.35, 10.0159, 10.4483),
    ("imagem_gerada_2_c1_4_img_1.35_guassblur_2.jpg", 1.35, 9.7793, 10.4086),
    ("imagem_gerada_5_c1_4_img_1.35_guassblur_10.jpg", 1.35, 9.9297, 10.6565),
    ("imagem_gerada_6_c1_4_img_1.35_guassblur_2.jpg", 1.35, 8.3425, 9.8406),
    ("imagem_gerada_7_c1_4_img_1.35_guassblur_10.jpg", 1.35, 7.1256, 9.2295),
    ("imagem_gerada_8_c1_4_img_1.35_guassblur_2.jpg", 1.35, 10.0740, 10.3278)
]

# Dados das imagens reais
dados_reais = [
        ("imagem_real_11_c1_4_img_1.33_guassblur_10.jpg", 1.33, -5.1520, 1.9712),
    ("imagem_real_12_c1_4_img_1.33_guassblur_2.jpg", 1.33, -5.5517, 0.6678),
    ("imagem_real_15_c1_4_img_1.33_guassblur_10.jpg", 1.33, -5.1166, 2.5815),
    ("imagem_real_16_c1_4_img_1.33_guassblur_2.jpg", 1.33, -6.8447, 2.5125),
    ("iimagem_real_17_c1_4_img_1.33_guassblur_10.jpg", 1.33, -5.3230, 1.9755),
    ("imagem_real_18_c1_4_img_1.33_guassblur_2.jpg", 1.33, -6.0723, 3.0772),
    ("imagem_real_1_c1_4_img_1.33_guassblur_10.jpg", 1.33, -5.2212, 1.9621),
    ("imagem_real_2_c1_4_img_1.33_guassblur_2.jpg", 1.33, -6.3364, 1.3672),
    ("imagem_real_5_c1_4_img_1.33_guassblur_10.jpg", 1.33, -5.1400, 2.5696),
    ("imagem_real_6_c1_4_img_1.33_guassblur_2.jpg", 1.33, -5.0558, 3.6790),
    ("imagem_real_7_c1_4_img_1.33_guassblur_10.jpg", 1.33, -5.3500, 1.9504),
    ("imagem_real_8_c1_4_img_1.33_guassblur_2.jpg", 1.33, -4.6501, 1.0467),
    ("imagem_real_11_c1_4_img_1.335_guassblur_10.jpg", 1.335, -2.4242, 2.2674),
    ("imagem_real_12_c1_4_img_1.335_guassblur_2.jpg", 1.335, -1.4740, 1.3684),
    ("iimagem_real_15_c1_4_img_1.335_guassblur_10.jpg", 1.335, -2.6704, 3.1481),
    ("imagem_real_16_c1_4_img_1.335_guassblur_2.jpg", 1.335, -2.0380, 4.1213),
    ("imagem_real_17_c1_4_img_1.335_guassblur_10.jpg", 1.335, -2.5291, 2.2604),
    ("imagem_real_18_c1_4_img_1.335_guassblur_2.jpg", 1.335, -2.9777, 1.3180),
    ("imagem_real_1_c1_4_img_1.335_guassblur_10.jpg", 1.335, -2.3968, 2.2720),
    ("imagem_real_2_c1_4_img_1.335_guassblur_2.jpg", 1.335, -2.1669, 0.5471),
    ("imagem_real_5_c1_4_img_1.335_guassblur_10.jpg", 1.335, -2.5730, 3.1791),
    ("imagem_real_6_c1_4_img_1.335_guassblur_2.jpg", 1.335, -3.1323, 4.2366),
    ("imagem_real_7_c1_4_img_1.335_guassblur_10.jpg", 1.335, -2.4535, 2.3024),
    ("imagem_real_8_c1_4_img_1.335_guassblur_2.jpg", 1.335, -1.4335, 2.4903),
    ("imagem_real_11_c1_4_img_1.34_guassblur_10.jpg", 1.34, 0.8553, 3.3715),
    ("imagem_real_12_c1_4_img_1.34_guassblur_2.jpg", 1.34, 1.6085, 1.9125),
    ("imagem_real_15_c1_4_img_1.34_guassblur_10.jpg", 1.34, 1.1077, 4.2241),
    ("imagem_real_16_c1_4_img_1.34_guassblur_2.jpg", 1.34, 0.4525, 5.4046),
    ("imagem_real_17_c1_4_img_1.34_guassblur_10.jpg", 1.34, 0.9785, 3.3700),
    ("imagem_real_18_c1_4_img_1.34_guassblur_2.jpg", 1.34, 0.5057, 2.2457),
    ("imagem_real_1_c1_4_img_1.34_guassblur_10.jpg", 1.34, 0.8956, 3.3864),
    ("imagem_real_2_c1_4_img_1.34_guassblur_2.jpg", 1.34, -0.1239, 3.9993),
    ("imagem_real_5_c1_4_img_1.34_guassblur_10.jpg", 1.34, 1.0825, 4.2424),
    ("imagem_real_6_c1_4_img_1.34_guassblur_2.jpg", 1.34, 1.6751, 5.0358),
    ("imagem_real_7_c1_4_img_1.34_guassblur_10.jpg", 1.34, 0.8914, 3.3549),
    ("imagem_real_8_c1_4_img_1.34_guassblur_2.jpg", 1.34, 2.0659, 2.9962),
    ("imagem_real_11_c1_4_img_1.345_guassblur_10.jpg", 1.345, 4.8471, 4.7794),
    ("imagem_real_12_c1_4_img_1.345_guassblur_2.jpg", 1.345, 4.1226, 3.8107),
    ("imagem_reala_15_c1_4_img_1.345_guassblur_10.jpg", 1.345, 5.5458, 5.1829),
    ("imagem_real_16_c1_4_img_1.345_guassblur_2.jpg", 1.345, 6.0103, 3.8063),
    ("imagem_real_17_c1_4_img_1.345_guassblur_10.jpg", 1.345, 4.7701, 4.8238),
    ("imagem_real_18_c1_4_img_1.345_guassblur_2.jpg", 1.345, 3.7434, 5.0944),
    ("imagem_real_1_c1_4_img_1.345_guassblur_10.jpg", 1.345, 4.8495, 4.8036),
    ("imagem_real_2_c1_4_img_1.345_guassblur_2.jpg", 1.345, 5.0488, 3.2352),
    ("imagem_real_5_c1_4_img_1.345_guassblur_10.jpg", 1.345, 5.5431, 5.1746),
    ("imagem_real_6_c1_4_img_1.345_guassblur_2.jpg", 1.345, 5.1167, 6.5262),
    ("imagem_real_7_c1_4_img_1.345_guassblur_10.jpg", 1.345, 4.7811, 4.8163),
    ("imagem_real_8_c1_4_img_1.345_guassblur_2.jpg", 1.345, 4.0119, 6.1222),
    ("imagem_real_11_c1_4_img_1.35_guassblur_10.jpg", 1.35, 7.2862, 5.6462),
    ("imagem_real_12_c1_4_img_1.35_guassblur_2.jpg", 1.35, 7.4207, 4.4525),
    ("imagem_real_15_c1_4_img_1.35_guassblur_10.jpg", 1.35, 7.8524, 5.8760),
    ("imagem_real_16_c1_4_img_1.35_guassblur_2.jpg", 1.35, 8.6574, 6.8162),
    ("imagem_real_17_c1_4_img_1.35_guassblur_10.jpg", 1.35, 7.2469, 5.6493),
    ("imagem_real_18_c1_4_img_1.35_guassblur_2.jpg", 1.35, 7.4706, 7.1572),
    ("imagem_real_1_c1_4_img_1.35_guassblur_10.jpg", 1.35, 7.2957, 5.6574),
    ("imagem_real_2_c1_4_img_1.35_guassblur_2.jpg", 1.35, 6.6640, 6.7078),
    ("imagem_real_5_c1_4_img_1.35_guassblur_10.jpg", 1.35, 7.8805, 5.8753),
    ("imagem_real_6_c1_4_img_1.35_guassblur_2.jpg", 1.35, 9.0459, 5.5969),
    ("imagem_real_7_c1_4_img_1.35_guassblur_10.jpg", 1.35, 7.2954, 5.6702),
    ("imagem_real_8_c1_4_img_1.35_guassblur_2.jpg", 1.35, 8.3355, 4.5808)
]

# Separar os dados
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches

# [Seus dados aqui... dados_gerados e dados_reais]

# Separar os dados
def processar_dados(dados):
    classes = [d[1] for d in dados]
    xs = [d[2] for d in dados]
    ys = [d[3] for d in dados]
    return classes, xs, ys

classes_gerados, xs_gerados, ys_gerados = processar_dados(dados_gerados)
classes_reais, xs_reais, ys_reais = processar_dados(dados_reais)

# Mapear cores por classe
color_map = {1.33: 'blue', 1.335: 'green', 1.34: 'red', 1.345: 'yellow', 1.35: 'purple'}
cores_gerados = [color_map[cl] for cl in classes_gerados]
cores_reais = [color_map[cl] for cl in classes_reais]

# Plotar gráfico combinado
fig, ax = plt.subplots(figsize=(12, 8))

# Plotar imagens geradas (com marcador estrela)
scatter_gerados = ax.scatter(xs_gerados, ys_gerados, c=cores_gerados, s=100,
                            marker='*', label='Geradas (*)')

# Plotar imagens reais (com marcador círculo)
scatter_reais = ax.scatter(xs_reais, ys_reais, c=cores_reais, s=70,
                          marker='o', label='Reais (○)')

# Configurações do gráfico
ax.set_xlabel('X', fontsize=12)
ax.set_ylabel('Y', fontsize=12)
#ax.set_title('Comparação t-SNE 2D: Imagens Geradas vs Reais (por classe)', fontsize=14)

# Criar legendas combinadas
legend_elements = [
    *[mpatches.Patch(color=color_map[cl], label=f'Classe {cl}') for cl in sorted(color_map.keys())],
    plt.Line2D([0], [0], marker='*', color='w', label='Geradas',
              markerfacecolor='gray', markersize=15),
    plt.Line2D([0], [0], marker='o', color='w', label='Reais',
              markerfacecolor='gray', markersize=10)
]

# Adicionar legenda única
plt.legend(handles=legend_elements, title="Legenda", bbox_to_anchor=(1.25, 1), loc='upper left')

plt.tight_layout()
plt.show()

import torch
import numpy as np
import matplotlib.pyplot as plt
from torchvision import transforms
from skimage.metrics import structural_similarity as ssim

# Caminho do arquivo contendo os dados salvos
caminho_arquivo = '/content/drive/My Drive/mestrado_16_03_2024/224X224_24_03_2025/Lista_gerada_DCGAN/10_02_2025_dadosC1_50_epocas_12_Imagens_gerada_rps_cada_classe.pt'

# Carregar os dados do arquivo
dados_carregados = torch.load(caminho_arquivo, weights_only=False)

# Function to calculate FFT (magnitude spectrum in log scale)
def calcular_fft(imagem):
    if isinstance(imagem, torch.Tensor):
        imagem = imagem.squeeze().cpu().numpy()
    f = np.fft.fft2(imagem)
    fshift = np.fft.fftshift(f)
    magnitude = 20 * np.log(np.abs(fshift) + 1)
    return magnitude

# Function to normalize image to tensor format
def normalizar_img(img):
    if isinstance(img, np.ndarray):
        img = torch.from_numpy(img)
    if not torch.is_tensor(img):
        img = transforms.ToTensor()(img)
    while img.dim() > 2:
        img = img.squeeze(0)
    return img

# Image names to process

#Nomes_Img = [
#    '2_c1_4_img_1.35_guassblur_2.jpg','5_c1_4_img_1.35_guassblur_10.jpg','6_c1_4_img_1.35_guassblur_2.jpg',
#    '17_c1_4_img_1.35_guassblur_10.jpg','6_c1_4_img_1.35_guassblur_2.jpg','7_c1_4_img_1.35_guassblur_10.jpg',
#]
Nomes_Img = [
    '2_c1_4_img_1.33_guassblur_2.jpg','5_c1_4_img_1.33_guassblur_10.jpg','6_c1_4_img_1.33_guassblur_2.jpg',
    '17_c1_4_img_1.33_guassblur_10.jpg','8_c1_4_img_1.33_guassblur_2.jpg','7_c1_4_img_1.33_guassblur_10.jpg',
]
#Nomes_Img = [
#    '2_c1_4_img_1.335_guassblur_2.jpg','5_c1_4_img_1.335_guassblur_10.jpg','6_c1_4_img_1.33_guassblur_2.jpg',
#    '17_c1_4_img_1.335_guassblur_10.jpg','8_c1_4_img_1.335_guassblur_2.jpg','7_c1_4_img_1.335_guassblur_10.jp',
#]

#Nomes_Img = [
#    '1_c1_4_img_1.34_guassblur_10.jpg','2_c1_4_img_1.34_guassblur_2.jpg','7_c1_4_img_1.34_guassblur_10.jpg',
#    '12_c1_4_img_1.34_guassblur_2.jpg','16_c1_4_img_1.34_guassblur_2.jpg','18_c1_4_img_1.34_guassblur_2.jpg',
#]

#Nomes_Img = [
#    '11_c1_4_img_1.345_guassblur_10.jpg','12_c1_4_img_1.345_guassblur_2.jpg','15_c1_4_img_1.345_guassblur_10.jpg',
#    '16_c1_4_img_1.345_guassblur_2.jpg','17_c1_4_img_1.345_guassblur_10.jpg','18_c1_4_img_1.345_guassblur_2.jpg',
#]

#Nomes_Img = [
  #'1_c1_4_img_1.35_guassblur_10.jpg','2_c1_4_img_1.35_guassblur_2.jpg','5_c1_4_img_1.35_guassblur_10.jpg',
  #'6_c1_4_img_1.35_guassblur_2.jpg','7_c1_4_img_1.35_guassblur_10.jpg','8_c1_4_img_1.35_guassblur_2.jpg',
#]




# Initialize storage lists
imgs_reais = []
imgs_geradas = []
ffts_reais = []
ffts_geradas = []

# Process each image
for nome in Nomes_Img:
    imagem_selecionada = next((item for item in dados_carregados if item['image_index'] == nome), None)

    if not imagem_selecionada:
        print(f"Imagem não encontrada: {nome}")
        continue

    # Process target image
    img_alvo = normalizar_img(imagem_selecionada['imagem_alvo'])
    imgs_reais.append(img_alvo)
    ffts_reais.append(calcular_fft(img_alvo))

    # Process generated image
    img_gerada = normalizar_img(imagem_selecionada['imagem_gerada'])
    assert img_gerada.dim() == 2, f"Imagem gerada tem {img_gerada.dim()} dimensões"
    imgs_geradas.append(img_gerada)
    ffts_geradas.append(calcular_fft(img_gerada))

# Plot the 4xN matrix
num_imgs = len(imgs_reais)
fig, axs = plt.subplots(4, num_imgs, figsize=(num_imgs * 2.2, 8))

for i in range(num_imgs):
    # Original images
    axs[0, i].imshow(imgs_reais[i].cpu().numpy(), cmap='gray')
    axs[0, i].set_title(f"Real {i+1}", fontsize=8)
    axs[0, i].axis('off')

    # Generated images
    axs[1, i].imshow(imgs_geradas[i].cpu().numpy(), cmap='gray')
    axs[1, i].set_title(f"Gerada {i+1}", fontsize=8)
    axs[1, i].axis('off')

    # Original FFTs
    axs[2, i].imshow(ffts_reais[i], cmap='hot')
    axs[2, i].set_title(f"FFT Real {i+1}", fontsize=8)
    axs[2, i].axis('off')

    # Generated FFTs
    axs[3, i].imshow(ffts_geradas[i], cmap='hot')
    axs[3, i].set_title(f"FFT Gerada {i+1}", fontsize=8)
    axs[3, i].axis('off')

plt.tight_layout()
plt.show()

import torch
import numpy as np
from torchvision.models import inception_v3
from torchvision import transforms

# Dispositivo
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Carregar os dados do .pt
caminho_arquivo = '/content/drive/My Drive/mestrado_16_03_2024/224X224_24_03_2025/Lista_gerada_DCGAN/10_02_2025_dadosC1_50_epocas_12_Imagens_gerada_rps_cada_classe.pt'
dados_carregados = torch.load(caminho_arquivo, weights_only=False)

# Transformação para InceptionV3
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# Modelo InceptionV3 sem camada final
inception = inception_v3(pretrained=True, transform_input=False)
inception.fc = torch.nn.Identity()
inception.eval().to(device)

# Função para extrair features
def extract_feature(tensor_gray):
    if tensor_gray.ndim == 2:
        tensor_gray = tensor_gray.unsqueeze(0)
    if tensor_gray.shape[0] == 1:
        tensor_rgb = tensor_gray.repeat(3, 1, 1)
    else:
        tensor_rgb = tensor_gray
    tensor_rgb = transform(tensor_rgb).unsqueeze(0).to(device)
    with torch.no_grad():
        features = inception(tensor_rgb)
    return features.cpu().numpy().squeeze()

# Extrair características
features_alvo = []
features_gerada = []

for item in dados_carregados:
    img_alvo = item['imagem_alvo']
    img_gerada = item['imagem_gerada']

    if isinstance(img_alvo, np.ndarray):
        img_alvo = torch.tensor(img_alvo)
    if isinstance(img_gerada, np.ndarray):
        img_gerada = torch.tensor(img_gerada)

    img_alvo = img_alvo.squeeze()
    img_gerada = img_gerada.squeeze()

    features_alvo.append(extract_feature(img_alvo))
    features_gerada.append(extract_feature(img_gerada))

# Converter listas para arrays numpy
features_alvo = np.array(features_alvo)
features_gerada = np.array(features_gerada)

# RBF Kernel
def rbf_kernel(x, y, sigma=1.0):
    x = x[:, np.newaxis, :]
    y = y[np.newaxis, :, :]
    return np.exp(-np.sum((x - y) ** 2, axis=2) / (2 * sigma ** 2))

# Calcular MMD
def compute_mmd(X, Y, sigma=1.0):
    Kxx = rbf_kernel(X, X, sigma)
    Kyy = rbf_kernel(Y, Y, sigma)
    Kxy = rbf_kernel(X, Y, sigma)
    m = X.shape[0]
    n = Y.shape[0]
    return Kxx.sum() / (m * m) + Kyy.sum() / (n * n) - 2 * Kxy.sum() / (m * n)

# Resultado final
mmd_score = compute_mmd(features_alvo, features_gerada, sigma=1.0)
print(f"MMD entre imagens alvo e geradas: {mmd_score:.4f}")

import torch
import numpy as np
import matplotlib.pyplot as plt

# Caminho do arquivo .pt com as 60 imagens
caminho_arquivo = '/content/drive/My Drive/mestrado_16_03_2024/224X224_24_03_2025/Lista_gerada_DCGAN/10_02_2025_dadosC1_50_epocas_12_Imagens_gerada_rps_cada_classe.pt'

# Carregar os dados
dados_carregados = torch.load(caminho_arquivo, weights_only=False)

# Inicializar somas dos histogramas
bins = 256
soma_hist_alvo = np.zeros(bins)
soma_hist_gerada = np.zeros(bins)
total_imagens = 0

# Loop pelas 60 imagens
for item in dados_carregados:
    # Imagem real
    img_alvo = item['imagem_alvo'].squeeze().cpu().numpy()
    img_alvo = ((img_alvo + 1) * 127.5).astype(np.uint8)
    hist_alvo, _ = np.histogram(img_alvo.ravel(), bins=bins, range=(0, 255))
    soma_hist_alvo += hist_alvo

    # Imagem gerada
    img_gerada = np.squeeze(item['imagem_gerada'])
    #img_gerada = item['imagem_gerada'].squeeze().cpu().numpy()
    img_gerada = ((img_gerada + 1) * 127.5).astype(np.uint8)
    hist_gerada, _ = np.histogram(img_gerada.ravel(), bins=bins, range=(0, 255))
    soma_hist_gerada += hist_gerada

    total_imagens += 1

# Calcular histogramas médios
hist_medio_alvo = soma_hist_alvo / total_imagens
hist_medio_gerada = soma_hist_gerada / total_imagens

# Plotar os histogramas médios
plt.figure(figsize=(10, 5))
plt.plot(hist_medio_alvo, label='Imagens Reais (média)', color='blue')
plt.plot(hist_medio_gerada, label='Imagens Geradas (média)', color='red')
#plt.title(f'Comparação de Histogramas Médios ({total_imagens} imagens Reais e {total_imagens} Geradas )')
plt.xlabel('Intensidade de Pixel (0-255)')
plt.ylabel('Frequência Média')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""4.13.3 - Exibir imgens transicionadas


"""

import os
import re
import numpy as np
import torch
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from sklearn.manifold import TSNE
from torchvision import transforms, datasets
from google.colab import drive
drive.mount('/content/drive')

# Caminho para as imagens
caminho_TSNE = "/content/drive/MyDrive/mestrado_16_03_2024/224X224_14_04_2025/transicao_entre_imagens/transicao_1335_A_134/todos/"


# Transformação das imagens
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Dataset personalizado que retorna nome da imagem
class CustomImageFolder(datasets.ImageFolder):
    def __getitem__(self, index):
        image, label = super().__getitem__(index)
        image_path = self.imgs[index][0]
        image_name = os.path.basename(image_path)
        return image, label, image_name

# Criar o dataset
dataset_TSNE = CustomImageFolder(root=caminho_TSNE, transform=transform)

# Inicializar listas
images_2 = []
labels_2 = []
image_names_2 = []

# Carregar dados do dataset
for image, label, image_name in dataset_TSNE:
    images_2.append(image.numpy())
    labels_2.append(label)
    image_names_2.append(image_name)

# Converter para 2D
images_2 = np.array([img.flatten() for img in images_2])

# Aplicar t-SNE
perplexity = 16
tsne = TSNE(n_components=2, init='random', random_state=0, perplexity=perplexity)
digits_proj = tsne.fit_transform(images_2)

# Definir cores
color_map = {0: 'green', 1: 'red', 2: 'black', 3: 'black'}
label_colors = [color_map[int(label)] for label in labels_2]

# Legenda
label_values = {0: 1.335, 1: 1.34, 2: 'Interpolação normal (Verde-Vermelho)', 3: 'Interpolação inversa (Vermelho-Verde)'}
legend_patches = [mpatches.Patch(color=color_map[label], label=f'{label_values[label]}') for label in color_map]

# Plot
fig, ax = plt.subplots(figsize=(14, 8))
ax.scatter(x=digits_proj[:, 0], y=digits_proj[:, 1], c=label_colors, s=100)

# Nomes das imagens a destacar
destacar_nomes = [

    "imagem_gerada_5_c1_4_img_1.34_guassblur_10.jpg",
    "imagem_gerada_2_c1_4_img_1.335_guassblur_2.jpg"

]


# Circular com cor amarela
for i, name in enumerate(image_names_2):
    if name in destacar_nomes:
        ax.scatter(digits_proj[i, 0], digits_proj[i, 1],
                   s=300, facecolors='none', edgecolors='yellow', linewidths=3)

# Adicionar número nas interpolações (label == 2)
for i, (x, y) in enumerate(digits_proj):
    if labels_2[i] == 2:
        numero = image_names_2[i].split('.')[0]
        ax.text(x, y, numero, fontsize=10, ha='center', va='center', color='white',
                bbox=dict(facecolor='black', alpha=0.7, edgecolor='none', boxstyle='round,pad=0.2'))
# Adicionar número nas interpolações (label == 2 ou label == 3)
for i, (x, y) in enumerate(digits_proj):
    if labels_2[i] in [2, 3]:
        numero = image_names_2[i].split('.')[0]
        ax.text(x, y, numero, fontsize=10, ha='center', va='center', color='white',
                bbox=dict(facecolor='black', alpha=0.7, edgecolor='none', boxstyle='round,pad=0.2'))

# Eixos e legenda
ax.set_xlabel("Eixo X", fontsize=12)
ax.set_ylabel("Eixo Y", fontsize=12)
plt.legend(handles=legend_patches, title="Rótulos", bbox_to_anchor=(1.2, 1), loc='upper left')

plt.tight_layout(rect=[0, 0, 1.0, 1])
plt.show()

import os
import matplotlib.pyplot as plt
from PIL import Image
from google.colab import drive

# Montar o Drive
drive.mount('/content/drive')

# Caminho das imagens
caminho_imagens = "/content/drive/MyDrive/mestrado_16_03_2024/224X224_14_04_2025/transicao_entre_imagens/transicao_1335_A_134/134_1335/1.34/"

# Verificar existência do diretório
if not os.path.exists(caminho_imagens):
    raise FileNotFoundError(f"Caminho não encontrado: {caminho_imagens}")

# Listar imagens
extensoes_validas = ['.jpg', '.jpeg', '.png']
lista_imagens = [f for f in os.listdir(caminho_imagens) if os.path.splitext(f)[1].lower() in extensoes_validas][:20]

# Plotar imagens com título maior
fig, axs = plt.subplots(2, 6, figsize=(20, 5))
for i, ax in enumerate(axs.flat):
    if i < len(lista_imagens):
        caminho_img = os.path.join(caminho_imagens, lista_imagens[i])
        img = Image.open(caminho_img).convert("RGB")
        ax.imshow(img)
        ax.set_title(lista_imagens[i], fontsize=12)
        ax.axis('off')
    else:
        ax.axis('off')

plt.tight_layout()
plt.show()

import os
import matplotlib.pyplot as plt
from PIL import Image
from google.colab import drive

# Montar o Drive
drive.mount('/content/drive')

# Caminho das imagens
caminho_imagens = "/content/drive/MyDrive/mestrado_16_03_2024/224X224_14_04_2025/transicao_entre_imagens/transicao_1335_A_134/todos/1335_a_134/"

# Verificar existência do diretório
if not os.path.exists(caminho_imagens):
    raise FileNotFoundError(f"Caminho não encontrado: {caminho_imagens}")

# Listar imagens
extensoes_validas = ['.jpg', '.jpeg', '.png']
lista_imagens = [f for f in os.listdir(caminho_imagens) if os.path.splitext(f)[1].lower() in extensoes_validas][:20]

# Plotar imagens com título maior
fig, axs = plt.subplots(3, 6, figsize=(18, 7))
for i, ax in enumerate(axs.flat):
    if i < len(lista_imagens):
        caminho_img = os.path.join(caminho_imagens, lista_imagens[i])
        img = Image.open(caminho_img).convert("RGB")
        ax.imshow(img)
        ax.set_title(lista_imagens[i], fontsize=12)
        ax.axis('off')
    else:
        ax.axis('off')

plt.tight_layout()
plt.show()

import os
import matplotlib.pyplot as plt
from PIL import Image
from google.colab import drive

# Montar o Drive
drive.mount('/content/drive')

# Caminho das imagens
caminho_imagens = "/content/drive/MyDrive/mestrado_16_03_2024/224X224_14_04_2025/transicao_entre_imagens/transicao_1335_A_134/todos/134_a_1335/"

# Verificar existência do diretório
if not os.path.exists(caminho_imagens):
    raise FileNotFoundError(f"Caminho não encontrado: {caminho_imagens}")

# Listar imagens
extensoes_validas = ['.jpg', '.jpeg', '.png']
lista_imagens = [f for f in os.listdir(caminho_imagens) if os.path.splitext(f)[1].lower() in extensoes_validas][:20]

# Plotar imagens com título maior
fig, axs = plt.subplots(3, 6, figsize=(18, 7))
for i, ax in enumerate(axs.flat):
    if i < len(lista_imagens):
        caminho_img = os.path.join(caminho_imagens, lista_imagens[i])
        img = Image.open(caminho_img).convert("RGB")
        ax.imshow(img)
        ax.set_title(lista_imagens[i], fontsize=12)
        ax.axis('off')
    else:
        ax.axis('off')

plt.tight_layout()
plt.show()

import os
import re
import numpy as np
import torch
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from sklearn.manifold import TSNE
from torchvision import transforms, datasets
from google.colab import drive
drive.mount('/content/drive')


# Caminho para as imagens
caminho_TSNE = "/content/drive/MyDrive/mestrado_16_03_2024/224X224_14_04_2025/transicao_entre_imagens/transicao_133_A_1335/todos/"


# Transformação das imagens
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Dataset personalizado que retorna nome da imagem
class CustomImageFolder(datasets.ImageFolder):
    def __getitem__(self, index):
        image, label = super().__getitem__(index)
        image_path = self.imgs[index][0]
        image_name = os.path.basename(image_path)
        return image, label, image_name

# Criar o dataset
dataset_TSNE = CustomImageFolder(root=caminho_TSNE, transform=transform)

# Inicializar listas
images_2 = []
labels_2 = []
image_names_2 = []

# Carregar dados do dataset
for image, label, image_name in dataset_TSNE:
    images_2.append(image.numpy())
    labels_2.append(label)
    image_names_2.append(image_name)

# Converter para 2D
images_2 = np.array([img.flatten() for img in images_2])

# Aplicar t-SNE
perplexity = 17
tsne = TSNE(n_components=2, init='random', random_state=0, perplexity=perplexity)
digits_proj = tsne.fit_transform(images_2)

# Definir cores
color_map = {0: 'blue', 1: 'green', 2: 'black', 3: 'black'}
label_colors = [color_map[int(label)] for label in labels_2]

# Legenda
label_values = {0: 1.33, 1: 1.335, 2: 'Interpolação normal (Azul-Verde', 3: 'Interpolação inversa (Verde-Azul)'}
legend_patches = [mpatches.Patch(color=color_map[label], label=f'{label_values[label]}') for label in color_map]

# Plot
fig, ax = plt.subplots(figsize=(14, 8))
ax.scatter(x=digits_proj[:, 0], y=digits_proj[:, 1], c=label_colors, s=100)

# Nomes das imagens a destacar
destacar_nomes = [

    "imagem_gerada_2_c1_4_img_1.33_guassblur_2.jpg",
    "imagem_gerada_16_c1_4_img_1.335_guassblur_2.jpg"

]


# Circular com cor amarela
for i, name in enumerate(image_names_2):
    if name in destacar_nomes:
        ax.scatter(digits_proj[i, 0], digits_proj[i, 1],
                   s=300, facecolors='none', edgecolors='yellow', linewidths=3)

# Adicionar número nas interpolações (label == 2)
for i, (x, y) in enumerate(digits_proj):
    if labels_2[i] == 2:
        numero = image_names_2[i].split('.')[0]
        ax.text(x, y, numero, fontsize=10, ha='center', va='center', color='white',
                bbox=dict(facecolor='black', alpha=0.7, edgecolor='none', boxstyle='round,pad=0.2'))
# Adicionar número nas interpolações (label == 2 ou label == 3)
for i, (x, y) in enumerate(digits_proj):
    if labels_2[i] in [2, 3]:
        numero = image_names_2[i].split('.')[0]
        ax.text(x, y, numero, fontsize=10, ha='center', va='center', color='white',
                bbox=dict(facecolor='black', alpha=0.7, edgecolor='none', boxstyle='round,pad=0.2'))

# Eixos e legenda
ax.set_xlabel("Eixo X", fontsize=12)
ax.set_ylabel("Eixo Y", fontsize=12)
plt.legend(handles=legend_patches, title="Rótulos", bbox_to_anchor=(1.2, 1), loc='upper left')

plt.tight_layout(rect=[0, 0, 1.0, 1])
plt.show()

import os
import matplotlib.pyplot as plt
from PIL import Image
from google.colab import drive

# Montar o Drive
drive.mount('/content/drive')

# Caminho das imagens
caminho_imagens = "/content/drive/MyDrive/mestrado_16_03_2024/224X224_14_04_2025/transicao_entre_imagens/transicao_133_A_1335/133_1335/133_A_1335/transicao/"

# Verificar existência do diretório
if not os.path.exists(caminho_imagens):
    raise FileNotFoundError(f"Caminho não encontrado: {caminho_imagens}")

# Listar imagens
extensoes_validas = ['.jpg', '.jpeg', '.png']
lista_imagens = [f for f in os.listdir(caminho_imagens) if os.path.splitext(f)[1].lower() in extensoes_validas][:20]

# Plotar imagens com título maior
fig, axs = plt.subplots(3, 6, figsize=(18, 7))
for i, ax in enumerate(axs.flat):
    if i < len(lista_imagens):
        caminho_img = os.path.join(caminho_imagens, lista_imagens[i])
        img = Image.open(caminho_img).convert("RGB")
        ax.imshow(img)
        ax.set_title(lista_imagens[i], fontsize=14)
        ax.axis('off')
    else:
        ax.axis('off')

plt.tight_layout()
plt.show()

import os
import matplotlib.pyplot as plt
from PIL import Image
from google.colab import drive

# Montar o Drive
drive.mount('/content/drive')

# Caminho das imagens
caminho_imagens = "/content/drive/MyDrive/mestrado_16_03_2024/224X224_14_04_2025/transicao_entre_imagens/transicao_133_A_1335/1335_133/1335_A_133/"

# Verificar existência do diretório
if not os.path.exists(caminho_imagens):
    raise FileNotFoundError(f"Caminho não encontrado: {caminho_imagens}")

# Listar imagens
extensoes_validas = ['.jpg', '.jpeg', '.png']
lista_imagens = [f for f in os.listdir(caminho_imagens) if os.path.splitext(f)[1].lower() in extensoes_validas][:20]

# Plotar imagens com título maior
fig, axs = plt.subplots(3, 6, figsize=(18, 7))
for i, ax in enumerate(axs.flat):
    if i < len(lista_imagens):
        caminho_img = os.path.join(caminho_imagens, lista_imagens[i])
        img = Image.open(caminho_img).convert("RGB")
        ax.imshow(img)
        ax.set_title(lista_imagens[i], fontsize=12)
        ax.axis('off')
    else:
        ax.axis('off')

plt.tight_layout()
plt.show()

import os
import matplotlib.pyplot as plt
from PIL import Image
from google.colab import drive

# Montar o Drive
drive.mount('/content/drive')

# Caminho das imagens
caminho_imagens = "/content/drive/MyDrive/mestrado_16_03_2024/224X224_14_04_2025/transicao_entre_imagens/transicao_133_A_1335/1335_133/1.33/"

# Verificar existência do diretório
if not os.path.exists(caminho_imagens):
    raise FileNotFoundError(f"Caminho não encontrado: {caminho_imagens}")

# Listar imagens
extensoes_validas = ['.jpg', '.jpeg', '.png']
lista_imagens = [f for f in os.listdir(caminho_imagens) if os.path.splitext(f)[1].lower() in extensoes_validas][:20]

# Plotar imagens com título maior
fig, axs = plt.subplots(2, 6, figsize=(20, 5))
for i, ax in enumerate(axs.flat):
    if i < len(lista_imagens):
        caminho_img = os.path.join(caminho_imagens, lista_imagens[i])
        img = Image.open(caminho_img).convert("RGB")
        ax.imshow(img)
        ax.set_title(lista_imagens[i], fontsize=12)
        ax.axis('off')
    else:
        ax.axis('off')

plt.tight_layout()
plt.show()

import os
import matplotlib.pyplot as plt
from PIL import Image
from google.colab import drive

# Montar o Drive
drive.mount('/content/drive')

# Caminho das imagens
caminho_imagens = "/content/drive/MyDrive/mestrado_16_03_2024/224X224_14_04_2025/transicao_entre_imagens/transicao_133_A_1335/1335_133/1.335/"

# Verificar existência do diretório
if not os.path.exists(caminho_imagens):
    raise FileNotFoundError(f"Caminho não encontrado: {caminho_imagens}")

# Listar imagens
extensoes_validas = ['.jpg', '.jpeg', '.png']
lista_imagens = [f for f in os.listdir(caminho_imagens) if os.path.splitext(f)[1].lower() in extensoes_validas][:20]

# Plotar imagens com título maior
fig, axs = plt.subplots(2, 6, figsize=(20, 5))
for i, ax in enumerate(axs.flat):
    if i < len(lista_imagens):
        caminho_img = os.path.join(caminho_imagens, lista_imagens[i])
        img = Image.open(caminho_img).convert("RGB")
        ax.imshow(img)
        ax.set_title(lista_imagens[i], fontsize=12)
        ax.axis('off')
    else:
        ax.axis('off')

plt.tight_layout()
plt.show()

import os
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from skimage import measure, filters, morphology

# --- CONFIGURAÇÕES INICIAIS ---
pasta_imagens = "/content/drive/My Drive/mestrado_16_03_2024/224X224_14_04_2025/operacao_vetor/soma_133_1335/"
nomes = [
    "6_c1_4_img_1.33_guassblur_2.jpg",
    "2_c1_4_img_1.335_guassblur_2.jpg",
    "soma.jpg"
]
classes = [
    "1.33",
    "1.335",
    "Classe Intermediária"
]
Nomes_ficticios = [
    "imagem1.jpg",
    "imagem2.jpg",
    "soma.jpg"
]

# Dicionário para substituir nomes originais pelos nomes personalizados
nomes_personalizados = {
    "6_c1_4_img_1.33_guassblur_2.jpg": "imagem1.jpg - classe 1.33",
    "2_c1_4_img_1.335_guassblur_2.jpg": "imagem1.jpg - classe 1.335",
    "soma.jpg": "soma.jpg"
}

# --- PROCESSAMENTO DAS IMAGENS PARA O GRÁFICO ---
images_2 = []
image_names_2 = []
for nome_arquivo in nomes:
    caminho_imagem = os.path.join(pasta_imagens, nome_arquivo)
    if os.path.exists(caminho_imagem):
        img = Image.open(caminho_imagem).convert("L")
        img_np = np.array(img, dtype=np.float32) / 255.0
        images_2.append(img_np)
        image_names_2.append(nomes_personalizados[nome_arquivo])  # Usa nome personalizado aqui
    else:
        print(f"Imagem {nome_arquivo} não encontrada.")

# Calcular curvas normalizadas
curvas = []
for img_np in images_2:
    curva = np.sum(img_np, axis=0)
    curva_normalizada = (curva - np.min(curva)) / (np.max(curva) - np.min(curva)) * img_np.shape[0]
    curvas.append(curva_normalizada)

# Cores para o gráfico
cores = ['red', 'yellow', 'black']

# --- PROCESSAMENTO DAS IMAGENS PARA A TABELA ---
resultados = []
for nome, classe in zip(nomes, classes):
    caminho = os.path.join(pasta_imagens, nome)
    img = Image.open(caminho).convert("L")
    img_np = np.array(img)
    thresh = filters.threshold_otsu(img_np)
    binarizada = img_np > thresh
    binarizada = morphology.remove_small_objects(binarizada, min_size=50)
    rotulado = measure.label(binarizada)
    props = measure.regionprops(rotulado)

    if props:
        maior = max(props, key=lambda x: x.area)
        resultados.append({
            "nome": nome,
            "classe": classe,
            "área": maior.area,
            "perímetro": maior.perimeter,
            "excentricidade": maior.eccentricity,
            "circularidade": 4 * np.pi * maior.area / (maior.perimeter ** 2) if maior.perimeter > 0 else 0,
            "solidez": maior.solidity,
            "extent": maior.extent,
        })
    else:
        print(f"Nenhuma região detectada em {nome}")

# Dados da tabela
colunas = ["Imagem", "Classe", "Área", "Perímetro", "Excentricidade", "Circularidade", "Solidez", "Extent"]
dados_tabela = []
for res, nome_ficticio in zip(resultados, Nomes_ficticios):
    dados_tabela.append([
        nome_ficticio,
        res["classe"],
        f"{res['área']}",
        f"{res['perímetro']:.2f}",
        f"{res['excentricidade']:.4f}",
        f"{res['circularidade']:.4f}",
        f"{res['solidez']:.4f}",
        f"{res['extent']:.4f}"
    ])

# --- PLOT COMBINADO (CURVAS + TABELA) ---
fig = plt.figure(figsize=(14, 10))

# Subplot para o gráfico das curvas
ax1 = plt.subplot2grid((4, 1), (0, 0), rowspan=3)
for curva, nome, cor in zip(curvas, image_names_2, cores):
    linewidth = 4 if nome == "imagem2.jpg - classe 1.335" else 2  # Ajusta linewidth pelo nome personalizado
    ax1.plot(curva, color=cor, linewidth=linewidth, label=nome)
ax1.set_xlabel("Coluna de Pixels\n\n", fontsize=12)
ax1.set_ylabel("Intensidade da Luz Refletida", fontsize=12)
ax1.set_title("Curvas de Intensidade", fontsize=16)
ax1.grid(True)
ax1.legend()

# Subplot para a tabela

ax2 = plt.subplot2grid((4, 1), (3, 0))
ax2.axis('off')

ax2.set_title("Tabela de Parâmetros Morfológicos", fontsize=16)
tabela = ax2.table(cellText=dados_tabela, colLabels=colunas, loc='center', cellLoc='center')
tabela.auto_set_font_size(False)
tabela.set_fontsize(10)
tabela.scale(1.2, 1.5)

# Mostrar a figura
plt.tight_layout()
plt.show()

import os
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from skimage import measure, filters, morphology

# --- CONFIGURAÇÕES INICIAIS ---
pasta_imagens = "/content/drive/My Drive/mestrado_16_03_2024/224X224_14_04_2025/operacao_vetor/soma_1335_134/2_/"
nomes = [
    "1_c1_4_img_1.34_guassblur_10.jpg",
    "5_c1_4_img_1.335_guassblur_10.jpg",
    "soma.jpg"
]
classes = [
    "1.335",
    "1.34",
    "Classe Intermediária"
]
Nomes_ficticios = [
    "imagem1.jpg",
    "imagem2.jpg",
    "soma.jpg"
]

# Dicionário para substituir nomes originais pelos nomes personalizados
nomes_personalizados = {
    "1_c1_4_img_1.34_guassblur_10.jpg": "imagem3.jpg - classe 1.335",
    "5_c1_4_img_1.335_guassblur_10.jpg": "imagem4.jpg - classe 1.34",
    "soma.jpg": "soma.jpg"
}

# --- PROCESSAMENTO DAS IMAGENS PARA O GRÁFICO ---
images_2 = []
image_names_2 = []
for nome_arquivo in nomes:
    caminho_imagem = os.path.join(pasta_imagens, nome_arquivo)
    if os.path.exists(caminho_imagem):
        img = Image.open(caminho_imagem).convert("L")
        img_np = np.array(img, dtype=np.float32) / 255.0
        images_2.append(img_np)
        image_names_2.append(nomes_personalizados[nome_arquivo])  # Usa nome personalizado aqui
    else:
        print(f"Imagem {nome_arquivo} não encontrada.")

# Calcular curvas normalizadas
curvas = []
for img_np in images_2:
    curva = np.sum(img_np, axis=0)
    curva_normalizada = (curva - np.min(curva)) / (np.max(curva) - np.min(curva)) * img_np.shape[0]
    curvas.append(curva_normalizada)

# Cores para o gráfico
cores = ['red', 'yellow', 'black']

# --- PROCESSAMENTO DAS IMAGENS PARA A TABELA ---
resultados = []
for nome, classe in zip(nomes, classes):
    caminho = os.path.join(pasta_imagens, nome)
    img = Image.open(caminho).convert("L")
    img_np = np.array(img)
    thresh = filters.threshold_otsu(img_np)
    binarizada = img_np > thresh
    binarizada = morphology.remove_small_objects(binarizada, min_size=50)
    rotulado = measure.label(binarizada)
    props = measure.regionprops(rotulado)

    if props:
        maior = max(props, key=lambda x: x.area)
        resultados.append({
            "nome": nome,
            "classe": classe,
            "área": maior.area,
            "perímetro": maior.perimeter,
            "excentricidade": maior.eccentricity,
            "circularidade": 4 * np.pi * maior.area / (maior.perimeter ** 2) if maior.perimeter > 0 else 0,
            "solidez": maior.solidity,
            "extent": maior.extent,
        })
    else:
        print(f"Nenhuma região detectada em {nome}")

# Dados da tabela
colunas = ["Imagem", "Classe", "Área", "Perímetro", "Excentricidade", "Circularidade", "Solidez", "Extent"]
dados_tabela = []
for res, nome_ficticio in zip(resultados, Nomes_ficticios):
    dados_tabela.append([
        nome_ficticio,
        res["classe"],
        f"{res['área']}",
        f"{res['perímetro']:.2f}",
        f"{res['excentricidade']:.4f}",
        f"{res['circularidade']:.4f}",
        f"{res['solidez']:.4f}",
        f"{res['extent']:.4f}"
    ])

# --- PLOT COMBINADO (CURVAS + TABELA) ---
fig = plt.figure(figsize=(14, 10))

# Subplot para o gráfico das curvas
ax1 = plt.subplot2grid((4, 1), (0, 0), rowspan=3)
for curva, nome, cor in zip(curvas, image_names_2, cores):
    linewidth = 4 if nome == "imagem2.jpg - classe 1.335" else 2  # Ajusta linewidth pelo nome personalizado
    ax1.plot(curva, color=cor, linewidth=linewidth, label=nome)
ax1.set_xlabel("Coluna de Pixels\n\n", fontsize=12)
ax1.set_ylabel("Intensidade da Luz Refletida", fontsize=12)
ax1.set_title("Curvas de Intensidade", fontsize=14)
ax1.grid(True)
ax1.legend()

# Subplot para a tabela
ax2 = plt.subplot2grid((4, 1), (3, 0))
ax2.axis('off')
ax2.set_title("Tabela de Parâmetros Morfológicos", fontsize=16)
tabela = ax2.table(cellText=dados_tabela, colLabels=colunas, loc='center', cellLoc='center')
tabela.auto_set_font_size(False)
tabela.set_fontsize(10)
tabela.scale(1.2, 1.5)

# Mostrar a figura
plt.tight_layout()
plt.show()

import os
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from skimage import measure, filters, morphology

# --- CONFIGURAÇÕES INICIAIS ---
#pasta_imagens = "/content/drive/My Drive/mestrado_16_03_2024/224X224_14_04_2025/operacao_vetor/soma_1335_134/2_/"
pasta_imagens = "/content/drive/My Drive/mestrado_16_03_2024/224X224_14_04_2025/operacao_vetor/substracao_133_1335/"
nomes = [
    "6_c1_4_img_1.33_guassblur_2.jpg",
    "2_c1_4_img_1.335_guassblur_2.jpg",
    "subtracao.jpg"
]
classes = [
    "1.335",
    "1.34",
    "Classe Intermediária"
]
Nomes_ficticios = [
    "imagem1.jpg",
    "imagem2.jpg",
    "subtracao.jpg"
]

# Dicionário para substituir nomes originais pelos nomes personalizados
nomes_personalizados = {
    "6_c1_4_img_1.33_guassblur_2.jpg": "imagem1.jpg - classe 1.33",
    "2_c1_4_img_1.335_guassblur_2.jpg": "imagem2.jpg - classe 1.335",
    "subtracao.jpg": "subtracao.jpg"
}

# --- PROCESSAMENTO DAS IMAGENS PARA O GRÁFICO ---
images_2 = []
image_names_2 = []
for nome_arquivo in nomes:
    caminho_imagem = os.path.join(pasta_imagens, nome_arquivo)
    if os.path.exists(caminho_imagem):
        img = Image.open(caminho_imagem).convert("L")
        img_np = np.array(img, dtype=np.float32) / 255.0
        images_2.append(img_np)
        image_names_2.append(nomes_personalizados[nome_arquivo])  # Usa nome personalizado aqui
    else:
        print(f"Imagem {nome_arquivo} não encontrada.")

# Calcular curvas normalizadas
curvas = []
for img_np in images_2:
    curva = np.sum(img_np, axis=0)
    curva_normalizada = (curva - np.min(curva)) / (np.max(curva) - np.min(curva)) * img_np.shape[0]
    curvas.append(curva_normalizada)

# Cores para o gráfico
cores = ['red', 'yellow', 'black']

# --- PROCESSAMENTO DAS IMAGENS PARA A TABELA ---
resultados = []
for nome, classe in zip(nomes, classes):
    caminho = os.path.join(pasta_imagens, nome)
    img = Image.open(caminho).convert("L")
    img_np = np.array(img)
    thresh = filters.threshold_otsu(img_np)
    binarizada = img_np > thresh
    binarizada = morphology.remove_small_objects(binarizada, min_size=50)
    rotulado = measure.label(binarizada)
    props = measure.regionprops(rotulado)

    if props:
        maior = max(props, key=lambda x: x.area)
        resultados.append({
            "nome": nome,
            "classe": classe,
            "área": maior.area,
            "perímetro": maior.perimeter,
            "excentricidade": maior.eccentricity,
            "circularidade": 4 * np.pi * maior.area / (maior.perimeter ** 2) if maior.perimeter > 0 else 0,
            "solidez": maior.solidity,
            "extent": maior.extent,
        })
    else:
        print(f"Nenhuma região detectada em {nome}")

# Dados da tabela
colunas = ["Imagem", "Classe", "Área", "Perímetro", "Excentricidade", "Circularidade", "Solidez", "Extent"]
dados_tabela = []
for res, nome_ficticio in zip(resultados, Nomes_ficticios):
    dados_tabela.append([
        nome_ficticio,
        res["classe"],
        f"{res['área']}",
        f"{res['perímetro']:.2f}",
        f"{res['excentricidade']:.4f}",
        f"{res['circularidade']:.4f}",
        f"{res['solidez']:.4f}",
        f"{res['extent']:.4f}"
    ])

# --- PLOT COMBINADO (CURVAS + TABELA) ---
fig = plt.figure(figsize=(14, 10))

# Subplot para o gráfico das curvas
ax1 = plt.subplot2grid((4, 1), (0, 0), rowspan=3)
for curva, nome, cor in zip(curvas, image_names_2, cores):
    linewidth = 4 if nome == "imagem2.jpg - classe 1.335" else 2  # Ajusta linewidth pelo nome personalizado
    ax1.plot(curva, color=cor, linewidth=linewidth, label=nome)
ax1.set_xlabel("Coluna de Pixels\n\n", fontsize=12)
ax1.set_ylabel("Intensidade da Luz Refletida", fontsize=12)
ax1.set_title("Curvas de Intensidade", fontsize=14)
ax1.grid(True)
ax1.legend()

# Subplot para a tabela
ax2 = plt.subplot2grid((4, 1), (3, 0))
ax2.axis('off')
ax2.set_title("Tabela de Parâmetros Morfológicos", fontsize=16)
tabela = ax2.table(cellText=dados_tabela, colLabels=colunas, loc='center', cellLoc='center')
tabela.auto_set_font_size(False)
tabela.set_fontsize(10)
tabela.scale(1.2, 1.5)

# Mostrar a figura
plt.tight_layout()
plt.show()

import os
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from skimage import measure, filters, morphology

# --- CONFIGURAÇÕES INICIAIS ---
#pasta_imagens = "/content/drive/My Drive/mestrado_16_03_2024/224X224_14_04_2025/operacao_vetor/soma_1335_134/2_/"
pasta_imagens = "/content/drive/My Drive/mestrado_16_03_2024/224X224_14_04_2025/operacao_vetor/substracao_1335_134/"
nomes = [
    "2_c1_4_img_1.335_guassblur_2.jpg",
    "1_c1_4_img_1.34_guassblur_10.jpg",
    "substracao.jpg"
]
classes = [
    "1.335",
    "1.34",
    "Classe Intermediária"
]
Nomes_ficticios = [
    "imagem1.jpg",
    "imagem2.jpg",
    "substracao.jpg"
]

# Dicionário para substituir nomes originais pelos nomes personalizados
nomes_personalizados = {
    "2_c1_4_img_1.335_guassblur_2.jpg": "imagem3.jpg - classe 1.335",
    "1_c1_4_img_1.34_guassblur_10.jpg": "imagem4.jpg - classe 1.34",
    "substracao.jpg": "substracao.jpg"
}

# --- PROCESSAMENTO DAS IMAGENS PARA O GRÁFICO ---
images_2 = []
image_names_2 = []
for nome_arquivo in nomes:
    caminho_imagem = os.path.join(pasta_imagens, nome_arquivo)
    if os.path.exists(caminho_imagem):
        img = Image.open(caminho_imagem).convert("L")
        img_np = np.array(img, dtype=np.float32) / 255.0
        images_2.append(img_np)
        image_names_2.append(nomes_personalizados[nome_arquivo])  # Usa nome personalizado aqui
    else:
        print(f"Imagem {nome_arquivo} não encontrada.")

# Calcular curvas normalizadas
curvas = []
for img_np in images_2:
    curva = np.sum(img_np, axis=0)
    curva_normalizada = (curva - np.min(curva)) / (np.max(curva) - np.min(curva)) * img_np.shape[0]
    curvas.append(curva_normalizada)

# Cores para o gráfico
cores = ['red', 'yellow', 'black']

# --- PROCESSAMENTO DAS IMAGENS PARA A TABELA ---
resultados = []
for nome, classe in zip(nomes, classes):
    caminho = os.path.join(pasta_imagens, nome)
    img = Image.open(caminho).convert("L")
    img_np = np.array(img)
    thresh = filters.threshold_otsu(img_np)
    binarizada = img_np > thresh
    binarizada = morphology.remove_small_objects(binarizada, min_size=50)
    rotulado = measure.label(binarizada)
    props = measure.regionprops(rotulado)

    if props:
        maior = max(props, key=lambda x: x.area)
        resultados.append({
            "nome": nome,
            "classe": classe,
            "área": maior.area,
            "perímetro": maior.perimeter,
            "excentricidade": maior.eccentricity,
            "circularidade": 4 * np.pi * maior.area / (maior.perimeter ** 2) if maior.perimeter > 0 else 0,
            "solidez": maior.solidity,
            "extent": maior.extent,
        })
    else:
        print(f"Nenhuma região detectada em {nome}")

# Dados da tabela
colunas = ["Imagem", "Classe", "Área", "Perímetro", "Excentricidade", "Circularidade", "Solidez", "Extent"]
dados_tabela = []
for res, nome_ficticio in zip(resultados, Nomes_ficticios):
    dados_tabela.append([
        nome_ficticio,
        res["classe"],
        f"{res['área']}",
        f"{res['perímetro']:.2f}",
        f"{res['excentricidade']:.4f}",
        f"{res['circularidade']:.4f}",
        f"{res['solidez']:.4f}",
        f"{res['extent']:.4f}"
    ])

# --- PLOT COMBINADO (CURVAS + TABELA) ---
fig = plt.figure(figsize=(14, 10))

# Subplot para o gráfico das curvas
ax1 = plt.subplot2grid((4, 1), (0, 0), rowspan=3)
for curva, nome, cor in zip(curvas, image_names_2, cores):
    linewidth = 4 if nome == "imagem2.jpg - classe 1.335" else 2  # Ajusta linewidth pelo nome personalizado
    ax1.plot(curva, color=cor, linewidth=linewidth, label=nome)
ax1.set_xlabel("Coluna de Pixels\n\n", fontsize=12)
ax1.set_ylabel("Intensidade da Luz Refletida", fontsize=12)
ax1.set_title("Curvas de Intensidade", fontsize=14)
ax1.grid(True)
ax1.legend()

# Subplot para a tabela
ax2 = plt.subplot2grid((4, 1), (3, 0))
ax2.axis('off')
ax2.set_title("Tabela de Parâmetros Morfológicos", fontsize=16)
tabela = ax2.table(cellText=dados_tabela, colLabels=colunas, loc='center', cellLoc='center')
tabela.auto_set_font_size(False)
tabela.set_fontsize(10)
tabela.scale(1.2, 1.5)

# Mostrar a figura
plt.tight_layout()
plt.show()

# function to print sample images
def printImages(images):
    for i in range(len(images)):
        ax = plt.subplot(1,len(images),i+1)
        ax.set_axis_off()
        ax = plt.imshow(images[i].view(224,224).cpu().numpy(), cmap='gray')
    plt.show()

# function to print multiple image lines
def printImageMatrix(imageData, title):
    numRows = len(imageData)

    n=0
    fig = plt.figure(1)
    fig.suptitle(title)
    for line in imageData:
        for i in range(len(line)):
            ax = fig.add_subplot(numRows,len(line),n+1)
            ax.set_axis_off()
            ax = plt.imshow(line[i].view(224,224).cpu().numpy(), cmap='gray')
            n+=1
    plt.savefig('image:' + str(title) + '.png')
    plt.show()

def printImages1(images):
    num_images = len(images)
    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 2, 2))

    if num_images == 1:
        axes = [axes]  # Se houver apenas uma imagem, axes não será uma lista

    for i, img in enumerate(images):
        img_array = img.squeeze()  # Remove dimensões extras
        if isinstance(img_array, torch.Tensor):
            img_array = img_array.cpu().numpy()  # Converte para NumPy array se necessário

        # Certifique-se de que a imagem esteja no formato correto (28x28 para MNIST)
        if img_array.ndim == 3 and img_array.shape[0] == 1:
            img_array = img_array[0]  # Remove o canal se for único

        if img_array.ndim == 2:
            # Imagem já está no formato correto
            axes[i].imshow(img_array, cmap='gray', interpolation='nearest')
        else:
            raise ValueError(f"Imagem tem formato inesperado: {img_array.shape}")

        axes[i].axis('off')  # Desliga os eixos para uma visualização limpa

    plt.show()

def busca_imagem(testloader, label, image_name):
    # Percorrer o testloader para encontrar a imagem com o rótulo e nome desejados
    for images, labels, names in testloader:
        # Para cada imagem, verificar se o rótulo e o nome correspondem
        for i in range(len(labels)):
            if labels[i].item() == label and names[i] == image_name:
                # Retorna a imagem, rótulo e nome
                return images[i], labels[i], names[i]

    # Caso a imagem não seja encontrada
    raise ValueError(f"Imagem com rótulo {label} e nome {image_name} não encontrada.")

def findLatentVector(G, z_i, image, maxEpochs=5000, patience=5):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # move imagem para o mesmo device
    image = image.to(device)

    # choose a random starting point
    z = torch.randn(1, z_i, 1, 1, device=device, requires_grad=True)

    # define the optimization problem (method, loss)
    z_optimizer = optim.Adam([z], lr = 0.01)
    criterion = nn.MSELoss(reduction='sum')

    # run optimization
    z_optimizer.zero_grad()

    last_loss = 10000
    no_change = 0
    for epoch in range(maxEpochs + 1):
        output = G(z)
        loss = criterion(output, image)
        loss.backward()
        z_optimizer.step()

        if last_loss - loss.item() < 0:
            no_change += 1
        else:
            no_change = 0

        if no_change >= patience:
            break

        last_loss = loss.item()

    return z.detach()

def Visualizar_Interpolaçao(G, z_i, classe1, Nome_img1, classe2, Nome_img2):#interpolação de um numero para outro
    # Encontrar imagens no conjunto de dados testloader
    img1, rotulo, nome_imagem = busca_imagem(testloader, classe1, Nome_img1)
    img2, rotulo, nome_imagem = busca_imagem(testloader, classe2, Nome_img2)

    # Busca a segunda imagem alvo
    print('Imagens retiradas do conjunto de dados:')
    printImages([img1])
    printImages([img2])

    # Encontrar os vetores do espaço latente que geram réplicas dessas imagens
    z1 = findLatentVector(G, z_i, img1, maxEpochs=5000)
    z2 = findLatentVector(G, z_i, img2, maxEpochs=5000)

    soma_z1_z2 =   z1 + z2

    with torch.no_grad():
        G.eval()
        image_soma2 = G(soma_z1_z2).cpu()
    printImages([image_soma2])

Visualizar_Interpolaçao(G,z_i, 0, "1_c1_4_img_1.33_guassblur_10.jpg", 1, "15_c1_4_img_1.335_guassblur_10.jpg" )#interpolação de um numero para outro
#Visualizar_Interpolaçao(G,z_i, 1, "15_c1_4_img_1.335_guassblur_10.jpg", 2, "11_c1_4_img_1.34_guassblur_10.jpg" )#interpolação de um numero para outro

#11_c1_4_img_1.35_guassblur_10.jpg
#1_c1_4_img_1.33_guassblur_10.jpg
caminho_arquivo = "/content/drive/My Drive/mestrado_16_03_2024/224X224_24_03_2025/60_img_continuar_4_0_.pt"
dados_carregados = torch.load(caminho_arquivo, weights_only=False)

imagens = []  # Armazena as imagens
ids = []      # Armazena os IDs correspondentes

for item in dados_carregados:
    imagens.append(item['imagem_gerada'])  # Adiciona a imagem
    ids.append(item['id'])                 # Adiciona o ID associado

printImages3(imagens, ids)  # Exibe as imagens com seus IDs

import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from sklearn.manifold import TSNE
from torchvision import transforms, datasets
import torch

# Caminhos
caminho_classes = "/content/drive/My Drive/mestrado_16_03_2024/224X224_14_04_2025/transicao_133_135_60img/classe_geradas"
caminho_transicao = "/content/drive/My Drive/mestrado_16_03_2024/224X224_14_04_2025/transicao_133_135_60img/transicao"

# Transformação
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Dataset personalizado
class CustomImageFolder(datasets.ImageFolder):
    def __getitem__(self, index):
        image, label = super().__getitem__(index)
        image_path = self.imgs[index][0]
        image_name = os.path.basename(image_path)
        return image, label, image_name

# Carrega classes
dataset_classes = CustomImageFolder(root=caminho_classes, transform=transform)
dataset_transicao = CustomImageFolder(root=caminho_transicao, transform=transform)

# Mapas de cor e legenda
cores_desejadas = {
    '1.33': 'blue',
    '1.335': 'green',
    '1.34': 'red',
    '1.345': 'yellow',
    '1.35': 'purple'
}
rotulos_legenda = {k: k for k in cores_desejadas}

# Cria os mapas (label numérico → cor/legenda)
color_map = {dataset_classes.class_to_idx[k]: cores_desejadas[k] for k in dataset_classes.class_to_idx}
label_values = {dataset_classes.class_to_idx[k]: rotulos_legenda[k] for k in dataset_classes.class_to_idx}

# Carrega dados das classes
images_cls, labels_cls, names_cls = [], [], []
for image, label, name in dataset_classes:
    images_cls.append(image.numpy().flatten())
    labels_cls.append(label)
    names_cls.append(name)

# Carrega dados da transição
images_trans, labels_trans, names_trans = [], [], []
for image, label, name in dataset_transicao:
    images_trans.append(image.numpy().flatten())
    labels_trans.append(label)
    names_trans.append(name)

# Converte para numpy arrays
X_cls = np.array(images_cls)
X_trans = np.array(images_trans)

# Aplica t-SNE separadamente para classes
tsne_cls = TSNE(n_components=2, init='random', random_state=0, perplexity=13)
proj_classes = tsne_cls.fit_transform(X_cls)

# Aplica t-SNE separadamente para transição
tsne_trans = TSNE(n_components=2, init='random', random_state=0, perplexity=13)
proj_transicao = tsne_trans.fit_transform(X_trans)

# Salva as posições (opcional)
np.save('proj_classes.npy', proj_classes)
np.save('proj_transicao.npy', proj_transicao)

# Cores dos pontos de classe
label_colors = [color_map[int(lbl)] for lbl in labels_cls]

# === PLOT ===
fig, ax = plt.subplots(figsize=(12, 8))

# 1. Plotar classes
ax.scatter(proj_classes[:, 0], proj_classes[:, 1], c=label_colors, s=100)

# 2. Plotar transição
for i, (x, y) in enumerate(proj_transicao):
    ax.scatter(x, y, c='black', s=100)
    numero = names_trans[i].split('.')[0]
    ax.text(x, y, numero, fontsize=10, ha='center', va='center', color='white',
            bbox=dict(facecolor='black', alpha=0.7, edgecolor='none', boxstyle='round,pad=0.2'))

# Destaques (opcional)
destacar_nomes = [
    "imagem_gerada_11_c1_4_img_1.35_guassblur_10.jpg",
    "imagem_gerada_1_c1_4_img_1.33_guassblur_10.jpg"
]
for i, name in enumerate(names_cls):
    if name in destacar_nomes:
        ax.scatter(proj_classes[i, 0], proj_classes[i, 1],
                   s=300, facecolors='none', edgecolors='yellow', linewidths=3)

# Legenda
legend_patches = [mpatches.Patch(color=color_map[label], label=label_values[label]) for label in color_map]
legend_patches.append(mpatches.Patch(color='black', label='transição'))
ax.legend(handles=legend_patches, title="Rótulos", bbox_to_anchor=(1.2, 1), loc='upper left')

# Eixos
ax.set_xlabel("Eixo X", fontsize=12)
ax.set_ylabel("Eixo Y", fontsize=12)
plt.tight_layout(rect=[0, 0, 1.0, 1])
plt.show()

import os
import numpy as np
import torch
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from sklearn.manifold import TSNE
from torchvision import transforms, datasets

# Caminho para as imagens
caminho_TSNE = "/content/drive/MyDrive/mestrado_16_03_2024/224X224_14_04_2025/transicao_entre_imagens/transicao_133_A_1335/133_1335/133_A_1335/"

# Transformação das imagens
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Dataset personalizado que retorna nome da imagem
class CustomImageFolder(datasets.ImageFolder):
    def __getitem__(self, index):
        image, label = super().__getitem__(index)
        image_path = self.imgs[index][0]
        image_name = os.path.basename(image_path)
        return image, label, image_name

# Criar o dataset
dataset_TSNE = CustomImageFolder(root=caminho_TSNE, transform=transform)

# Listas para armazenar dados
images_2 = []
labels_2 = []
image_names_2 = []

# Carregar dados do dataset
for image, label, image_name in dataset_TSNE:
    images_2.append(image.numpy())  # Converter para NumPy
    labels_2.append(label)
    image_names_2.append(image_name)

# Lista de nomes a serem destacados (em ordem desejada)
destacar_nomes = [
    "1.jpg", "2.jpg", "3.jpg", "4.jpg", "5.jpg",
    "6.jpg", "7.jpg", "8.jpg", "9.jpg", "10.jpg",
    "11.jpg", "12.jpg", "13.jpg", "14.jpg", "15.jpg",
    "2_c1_4_img_1.33_guassblur_2.jpg",
    "16_c1_4_img_1.335_guassblur_2.jpg"
]

# Dicionário para mapear nomes antigos para novos nomes
mapa_nomes = {
    "2_c1_4_img_1.33_guassblur_2.jpg": "imagem8.jpg - classe 1.33",
    "16_c1_4_img_1.335_guassblur_2.jpg": "imagem4jpg - classe 1.335"
}

# Função para calcular métricas
def calcular_fwhm_max_min_gerada(curva_normalizada_gerada):
    max_value_gerada = np.max(curva_normalizada_gerada)
    min_value_gerada = np.min(curva_normalizada_gerada)
    fwhm_value_gerada = (max_value_gerada - min_value_gerada) / 2.0
    fwhm_line_gerada = min_value_gerada + fwhm_value_gerada
    min_index_gerada = np.argmin(curva_normalizada_gerada)
    return fwhm_value_gerada, fwhm_line_gerada, min_value_gerada, max_value_gerada, min_index_gerada

# Preparar variáveis para armazenar curvas
curvas = []
nomes_imagens_selecionadas = []

# Coletar curvas apenas das imagens destacadas
for nome_destacado in destacar_nomes:
    for img_np_gerada, nome_imagem in zip(images_2, image_names_2):
        if nome_imagem == nome_destacado:
            img_np_gerada = np.squeeze(img_np_gerada)
            img_np_gerada = ((img_np_gerada + 1) * 127.5).astype(np.uint8)

            curva_gerada = np.sum(img_np_gerada, axis=0)
            curva_normalizada_visual_gerada = (curva_gerada - np.min(curva_gerada)) / (np.max(curva_gerada) - np.min(curva_gerada)) * img_np_gerada.shape[0]

            curvas.append(curva_normalizada_visual_gerada)
            nomes_imagens_selecionadas.append(nome_imagem)
            break

# Gerar cores do azul ao verde para as 15 primeiras imagens
colormap = cm.get_cmap('winter', 15)
cores_base = [colormap(i) for i in range(15)]

# Duas imagens extras devem ser pretas e vermelha
cores = cores_base + ['black', 'red']

# Criar o gráfico
fig, ax = plt.subplots(figsize=(10, 8))

for curva, nome, cor in zip(curvas, nomes_imagens_selecionadas, cores):
    nome_exibido = mapa_nomes.get(nome, nome)  # Substitui se nome estiver no dicionário, senão mantém original
    ax.plot(curva, linewidth=2, color=cor, label=f"{nome_exibido}")

ax.legend()
plt.xlabel('Coluna de Pixels', fontsize=12)
plt.ylabel('Intensidade da Luz Refletida', fontsize=12)
plt.grid(True)
plt.tight_layout()

# Mostrar o gráfico
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Dados das posições (x, y) das imagens
coords = np.array([
    [-2.69, -3.06],  # 1.jpg
    [-2.88, -2.61],  # 2.jpg
    [-3.34, -2.31],  # 3.jpg
    [-3.93, -1.94],  # 4.jpg
    [-4.56, -1.54],  # 5.jpg
    [-5.19, -1.13],  # 6.jpg
    [-5.85, -0.70],  # 7.jpg
    [-6.43, -0.32],  # 8.jpg
    [-6.98,  0.01],  # 9.jpg
    [-7.42,  0.35],  # 10.jpg
    [-7.88,  0.41],  # 11.jpg
    [-8.03,  0.90],  # 12.jpg
    [-8.34,  0.94],  # 13.jpg
    [-8.59,  0.56],  # 14.jpg
    [-8.68,  0.60],  # 15.jpg
])





#Define P1 (classe 1.330) e P2 (classe 1.335) pelas coordenadas reais
P1 = np.array([-2.69, -3.06])
P2 = np.array([-8.68,  0.60])

classe_P1 = 1.330
classe_P2 = 1.335

# Distância total entre P1 e P2
dist_total = np.linalg.norm(P2 - P1)


# Cria uma lista vazia para armazenar os valores de classe estimados para cada ponto
classes_est = []

# Para cada ponto na lista de coordenadas 'coords'
for point in coords:
    dist_i = np.linalg.norm(point - P1)  # Calcula a distância euclidiana entre o ponto atual e o ponto inicial P1

    # Interpola a classe do ponto atual com base na distância relativa entre P1 e P2
    # A ideia é: quanto mais próximo de P2, mais o valor da classe se aproxima de classe_P2
    # quanto mais próximo de P1, mais o valor da classe se aproxima de classe_P1
    classe_i = classe_P1 + (dist_i / dist_total) * (classe_P2 - classe_P1)

    # Adiciona a classe estimada à lista
    classes_est.append(classe_i)

# Converte a lista para um array numpy, facilitando o uso posterior em operações vetoriais
classes_est = np.array(classes_est)

# Gráfico
plt.figure(figsize=(10, 6))
scatter = plt.scatter(coords[:, 0], coords[:, 1], c=classes_est, cmap='winter', s=300, edgecolor='black')
plt.plot(coords[:, 0], coords[:, 1], linestyle='--', color='gray', alpha=0.5)

# Adiciona os rótulos com as classes
for i, txt in enumerate(classes_est):
    plt.text(coords[i, 0], coords[i, 1]+0.25, f'{txt:.4f}', ha='center', fontsize=8)

# Adiciona o número (nome) dentro da bolinha
for i in range(len(coords)):
    plt.text(coords[i, 0], coords[i, 1], str(i+1), color='white', ha='center', va='center',
             fontsize=8, bbox=dict(facecolor='black', edgecolor='none', boxstyle='circle,pad=0.2'))

#plt.title("Plotando as novas Classes 1.331, 1.332, 1.333 e 1.334 usando TSNE")
plt.xlabel("X")
plt.ylabel("Y")
cbar = plt.colorbar(scatter)
cbar.set_label("Classes Estimada")
plt.grid(True)
plt.tight_layout()
plt.show()

import os
import re
import numpy as np
import torch
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from sklearn.manifold import TSNE
from torchvision import transforms, datasets

# Caminho para as imagens
caminho_TSNE = "/content/drive/MyDrive/mestrado_16_03_2024/224X224_14_04_2025/transicao_entre_imagens_120/todos/"


# Transformação das imagens
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Dataset personalizado que retorna nome da imagem
class CustomImageFolder(datasets.ImageFolder):
    def __getitem__(self, index):
        image, label = super().__getitem__(index)
        image_path = self.imgs[index][0]
        image_name = os.path.basename(image_path)
        return image, label, image_name

# Criar o dataset
dataset_TSNE = CustomImageFolder(root=caminho_TSNE, transform=transform)

# Inicializar listas
images_2 = []
labels_2 = []
image_names_2 = []

# Carregar dados do dataset
for image, label, image_name in dataset_TSNE:
    images_2.append(image.numpy())
    labels_2.append(label)
    image_names_2.append(image_name)

# Converter para 2D
images_2 = np.array([img.flatten() for img in images_2])

# Aplicar t-SNE
perplexity = 16
tsne = TSNE(n_components=2, init='random', random_state=0, perplexity=perplexity)
digits_proj = tsne.fit_transform(images_2)

# Definir cores
color_map = {0: 'blue', 1: 'green', 2: 'black', 3: 'black'}
label_colors = [color_map[int(label)] for label in labels_2]

# Legenda
label_values = {0: 1.33, 1: 1.335, 2: 'Transição(Azul-Verde)', 3: 'Transição(Verde-Azul)'}
legend_patches = [mpatches.Patch(color=color_map[label], label=f'{label_values[label]}') for label in color_map]

# Plot
fig, ax = plt.subplots(figsize=(16, 8))
ax.scatter(x=digits_proj[:, 0], y=digits_proj[:, 1], c=label_colors, s=100)

# Nomes das imagens a destacar
destacar_nomes = [

    "imagem_gerada_6_c1_4_img_1.33_guassblur_2.jpg",
    "imagem_gerada_2_c1_4_img_1.335_guassblur_2.jpg"

]


# Circular com cor amarela
for i, name in enumerate(image_names_2):
    if name in destacar_nomes:
        ax.scatter(digits_proj[i, 0], digits_proj[i, 1],
                   s=300, facecolors='none', edgecolors='yellow', linewidths=3)

# Adicionar número nas interpolações (label == 2)
for i, (x, y) in enumerate(digits_proj):
    if labels_2[i] == 2:
        numero = image_names_2[i].split('.')[0]
        ax.text(x, y, numero, fontsize=10, ha='center', va='center', color='white',
                bbox=dict(facecolor='black', alpha=0.7, edgecolor='none', boxstyle='round,pad=0.2'))
# Adicionar número nas interpolações (label == 2 ou label == 3)
for i, (x, y) in enumerate(digits_proj):
    if labels_2[i] in [2, 3]:
        numero = image_names_2[i].split('.')[0]
        ax.text(x, y, numero, fontsize=10, ha='center', va='center', color='white',
                bbox=dict(facecolor='black', alpha=0.7, edgecolor='none', boxstyle='round,pad=0.2'))

# Eixos e legenda
ax.set_xlabel("Eixo X", fontsize=12)
ax.set_ylabel("Eixo Y", fontsize=12)
#ax.set_xlim(-50, 50)
#ax.set_ylim(-30, 30)
plt.legend(handles=legend_patches, title="Rótulos", bbox_to_anchor=(1.2, 1), loc='upper left')
plt.tight_layout(rect=[0, 0, 1.0, 1])
plt.show()

import torch
import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import skew
import os
from matplotlib.gridspec import GridSpec

# Caminho do arquivo contendo os dados salvos
caminho_arquivo = '/content/drive/My Drive/mestrado_16_03_2024/224X224_24_03_2025/Lista_gerada_DCGAN/10_02_2025_dadosC1_50_epocas_12_Imagens_gerada_rps_cada_classe.pt'

# Carregar os dados do arquivo
dados_carregados = torch.load(caminho_arquivo, weights_only=False)

# Nome da imagem selecionada
#nome_img_1 = "16_c1_4_img_1.33_guassblur_2.jpg"
nome_img_1 = "16_c1_4_img_1.335_guassblur_2.jpg"
#nome_img_1 = "6_c1_4_img_1.34_guassblur_2.jpg"
#nome_img_1 = "16_c1_4_img_1.345_guassblur_2.jpg"
#nome_img_1 = "15_c1_4_img_1.35_guassblur_10.jpg"

# Encontrar a imagem correspondente
imagem_selecionada = next(
    (item for item in dados_carregados if item['image_index'] == nome_img_1),
    None
)

# Pré-processamento da imagem alvo
img_alvo1 = imagem_selecionada['imagem_alvo']
img_np_alvo = img_alvo1.squeeze().cpu().numpy()
img_np_alvo = ((img_np_alvo + 1) * 127.5).astype(np.uint8)

# Pré-processamento da imagem gerada
img_gerada1 = imagem_selecionada['imagem_gerada']
img_np_gerada = img_gerada1.squeeze()
img_np_gerada = ((img_np_gerada + 1) * 127.5).astype(np.uint8)

# Funções para cálculo das métricas
def calcular_fwhm_max_min(curva_normalizada):
    max_value = np.max(curva_normalizada)
    min_value = np.min(curva_normalizada)
    fwhm_value = (max_value - min_value) / 2.0
    fwhm_line = min_value + fwhm_value
    min_index = np.argmin(curva_normalizada)

    cl = np.where(curva_normalizada[:min_index] >= fwhm_line)[0]
    cr = np.where(curva_normalizada[min_index:] >= fwhm_line)[0]

    cl = cl[-1] if len(cl) > 0 else min_index
    cr = min_index + cr[0] if len(cr) > 0 else min_index

    cl_ajustado = min_index - cl
    cr_ajustado = cr - min_index
    largura_total = cl_ajustado + cr_ajustado

    return fwhm_value, fwhm_line, min_value, cl_ajustado, cr_ajustado, largura_total, min_index

# Cálculos para imagem alvo
curva_alvo = np.sum(img_np_alvo, axis=0)
curva_visual_alvo = (curva_alvo - np.min(curva_alvo)) / (np.max(curva_alvo) - np.min(curva_alvo)) * img_np_alvo.shape[0]
curva_energia_alvo = (curva_alvo - np.min(curva_alvo)) / (np.max(curva_alvo) - np.min(curva_alvo))

fwhm_alvo, _, _, _, _, largura_alvo, min_idx_alvo = calcular_fwhm_max_min(curva_visual_alvo)
energia_alvo = np.sum(curva_energia_alvo ** 2)
assimetria_alvo = skew(curva_visual_alvo)

# Cálculos para imagem gerada
curva_gerada = np.sum(img_np_gerada, axis=0)
curva_visual_gerada = (curva_gerada - np.min(curva_gerada)) / (np.max(curva_gerada) - np.min(curva_gerada)) * img_np_gerada.shape[0]
curva_energia_gerada = (curva_gerada - np.min(curva_gerada)) / (np.max(curva_gerada) - np.min(curva_gerada))

fwhm_gerada, _, _, _, _, largura_gerada, min_idx_gerada = calcular_fwhm_max_min(curva_visual_gerada)
energia_gerada = np.sum(curva_energia_gerada ** 2)
assimetria_gerada = skew(curva_visual_gerada)
##################################################################################################################################################################
# Listas para armazenar os valores de cada métrica
fwhm_list = []
largura_list = []
energia_list = []
assimetria_list = []
min_idx_list = []

for img_tensor, label, nome_img in dataset_trainloader:
    if label != 1:
        continue

    img_alvo = img_tensor.squeeze()
    img_alvo = ((img_alvo + 1) * 127.5).detach().numpy().astype(np.uint8)

    curva_alvo = np.sum(img_alvo, axis=0)
    curva_norm_vis_alvo = (curva_alvo - np.min(curva_alvo)) / (np.max(curva_alvo) - np.min(curva_alvo)) * img_alvo.shape[0]
    curva_norm_energia_alvo = (curva_alvo - np.min(curva_alvo)) / (np.max(curva_alvo) - np.min(curva_alvo))

    energia_i = np.sum(curva_norm_energia_alvo ** 2)
    assimetria_i = skew(curva_norm_vis_alvo)

    # Aqui é o ponto do erro: pegue só os 3 que você quer
    fwhm_i, _, _, _, _, largura_i, min_idx_i = calcular_fwhm_max_min(curva_norm_vis_alvo)

    # Armazenar métricas
    fwhm_list.append(fwhm_i)
    largura_list.append(largura_i)
    energia_list.append(energia_i)
    assimetria_list.append(assimetria_i)
    min_idx_list.append(min_idx_i)



##################################################################################################################################################################

# Dados para a tabela
dados_tabela = [
    ["", "FWHM", "Largura Total (LT)", "Energia Normalizada (EN)", "Assimetria", "Ponto Mínimo (PM)"],

    ["valores aceitaveis da classe 1,335",
        f"{min(fwhm_list):.2f} a {max(fwhm_list):.2f}",
        f"{min(largura_list)} a {max(largura_list)}",
        f"{min(energia_list):.2f} a {max(energia_list):.2f}",
        f"{min(assimetria_list):.2f} a {max(assimetria_list):.2f}",
        f"{min(min_idx_list)} a {max(min_idx_list)}"
        ],

    ["Imagem Original", f"{fwhm_alvo:.2f}", f"{largura_alvo}", f"{energia_alvo:.2f}", f"{assimetria_alvo:.2f}", f"{min_idx_alvo}"],
    ["Imagem Gerada", f"{fwhm_gerada:.2f}", f"{largura_gerada}", f"{energia_gerada:.2f}", f"{assimetria_gerada:.2f}", f"{min_idx_gerada}"]
]

# Criar figura com GridSpec
fig = plt.figure(figsize=(18, 8))
gs = GridSpec(2, 3, height_ratios=[3, 1])  # Linha 0: imagens e gráfico / Linha 1: tabela

# Gráfico de curvas
ax1 = fig.add_subplot(gs[0, 0])
ax1.plot(curva_visual_alvo, label="Imagem Origiinal", linewidth=2, color='blue')
ax1.plot(curva_visual_gerada, label="Imagem Gerada", linewidth=2, color='red')
#ax1.set_title(f"Curvas de Intensidade - {nome_img_1}", fontsize=10)
ax1.set_xlabel("Pixels")
ax1.set_ylabel("Intensidade")
ax1.grid(True)
ax1.legend()

# Imagem original
ax2 = fig.add_subplot(gs[0, 1])
ax2.imshow(img_alvo1.squeeze(0), cmap='gray')
ax2.set_title("Imagem Original")
ax2.axis('off')

# Imagem gerada
ax3 = fig.add_subplot(gs[0, 2])
ax3.imshow(img_gerada1.squeeze(), cmap='gray')
ax3.set_title("Imagem Gerada")
ax3.axis('off')

# Tabela na linha inferior
ax4 = fig.add_subplot(gs[1, :])
ax4.axis('off')

tabela = ax4.table(
    cellText=dados_tabela,
    loc='center',
    cellLoc='center',
    colWidths=[0.15]*6
)
tabela.auto_set_font_size(False)
tabela.set_fontsize(10)
tabela.scale(1.2, 1.5)

plt.tight_layout(pad=3.0)
plt.show()

import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# Pasta da classe 1.33
pasta_classe = '/content/drive/My Drive/mestrado_16_03_2024/224X224_14_04_2025/IMAGENS_GERADA_DCGAN/1.35'

images_2 = []
image_names_2 = []

# Carregar imagens .jpg da pasta
for nome_arquivo in sorted(os.listdir(pasta_classe)):
    if nome_arquivo.endswith('.jpg'):
        caminho = os.path.join(pasta_classe, nome_arquivo)
        img = Image.open(caminho).convert('L')  # grayscale
        img_np = np.array(img)
        images_2.append(img_np)
        image_names_2.append(nome_arquivo)

# Função para calcular a curva da imagem
def calcula_curva(img_np):
    # soma dos pixels em cada coluna
    curva = np.sum(img_np, axis=0)
    # normalizar para faixa [0, altura da imagem]
    curva_normalizada = (curva - np.min(curva)) / (np.max(curva) - np.min(curva))
    curva_normalizada *= img_np.shape[0]
    return curva_normalizada

curvas = [calcula_curva(img) for img in images_2]

# Cores para plotar (repetir se necessário)
cores = ['black','blue', 'yellow', 'red', 'green', 'orange', 'purple', 'cyan', 'magenta', 'lime', 'pink', 'brown']

fig, ax = plt.subplots(figsize=(10, 8))


for i, (curva, cor) in enumerate(zip(curvas, cores), start=1):
    ax.plot(curva, linewidth=1.5, color=cor, label=f'Imagem {i}')

ax.legend(fontsize=8)
ax.set_xlabel('Coluna de Pixels', fontsize=12)
ax.set_ylabel('Intensidade da Luz Refletida', fontsize=12)
ax.grid(True)
plt.tight_layout()
plt.show()

import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# Pasta da classe 1.33
pasta_classe = '/content/drive/My Drive/mestrado_16_03_2024/224X224_14_04_2025/IMAGENS_GERADA_DCGAN/1.33'

images_2 = []
image_names_2 = []

# Carregar imagens .jpg da pasta
for nome_arquivo in sorted(os.listdir(pasta_classe)):
    if nome_arquivo.endswith('.jpg'):
        caminho = os.path.join(pasta_classe, nome_arquivo)
        img = Image.open(caminho).convert('L')  # grayscale
        img_np = np.array(img)
        images_2.append(img_np)
        image_names_2.append(nome_arquivo)

# Função para calcular a curva da imagem
def calcula_curva(img_np):
    # soma dos pixels em cada coluna
    curva = np.sum(img_np, axis=0)
    # normalizar para faixa [0, altura da imagem]
    curva_normalizada = (curva - np.min(curva)) / (np.max(curva) - np.min(curva))
    curva_normalizada *= img_np.shape[0]
    return curva_normalizada

curvas = [calcula_curva(img) for img in images_2]

# Cores para plotar (repetir se necessário)
cores = ['black','blue', 'yellow', 'red', 'green', 'orange', 'purple', 'cyan', 'magenta', 'lime', 'pink', 'brown']

fig, ax = plt.subplots(figsize=(10, 8))

for curva, nome, cor in zip(curvas, image_names_2, cores):
    ax.plot(curva, linewidth=1.5, color=cor, label=nome)

ax.legend(fontsize=6)
#plt.title("Curva de Cada Imagens da Classe 1.33", fontsize=14)
ax.set_xlabel('Coluna de Pixels', fontsize=12)
ax.set_ylabel('Intensidade da Luz Refletida', fontsize=12)
ax.grid(True)
plt.tight_layout()
plt.show()